{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3d88ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym.spaces\n",
    "\n",
    "DEFAULT_ENV_NAME = \"PongNoFrameskip-v4\" \n",
    "test_env = gym.make(DEFAULT_ENV_NAME)\n",
    "print(test_env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "233c7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d76cd1",
   "metadata": {},
   "source": [
    "Environment Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a675e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from \n",
    "# https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/blob/master/Chapter06/lib/wrappers.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(FireResetEnv, self).__init__(env)\n",
    "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        obs, _, done, _ = self.env.step(1)\n",
    "        if done:\n",
    "            self.env.reset()\n",
    "        obs, _, done, _ = self.env.step(2)\n",
    "        if done:\n",
    "            self.env.reset()\n",
    "        return obs\n",
    "\n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None, skip=4):\n",
    "        super(MaxAndSkipEnv, self).__init__(env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = collections.deque(maxlen=2)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for _ in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            self._obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self._obs_buffer.clear()\n",
    "        obs = self.env.reset()\n",
    "        self._obs_buffer.append(obs)\n",
    "        return obs\n",
    "\n",
    "\n",
    "class ProcessFrame84(gym.ObservationWrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(ProcessFrame84, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return ProcessFrame84.process(obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "        if frame.size == 210 * 160 * 3:\n",
    "            img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
    "        elif frame.size == 250 * 160 * 3:\n",
    "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
    "        else:\n",
    "            assert False, \"Unknown resolution.\"\n",
    "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
    "        x_t = resized_screen[18:102, :]\n",
    "        x_t = np.reshape(x_t, [84, 84, 1])\n",
    "        return x_t.astype(np.uint8)\n",
    "\n",
    "\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_steps, dtype=np.float32):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.dtype = dtype\n",
    "        old_space = env.observation_space\n",
    "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
    "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
    "        return self.observation(self.env.reset())\n",
    "\n",
    "    def observation(self, observation):\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1] = observation\n",
    "        return self.buffer\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], \n",
    "                                old_shape[0], old_shape[1]), dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "def make_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = FireResetEnv(env)\n",
    "    env = ProcessFrame84(env)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env = BufferWrapper(env, 4)\n",
    "    return ScaledFloatFrame(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd94e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(DEFAULT_ENV_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06f2125",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e3dc64cb437e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyTorchRL\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m __all__ += [name for name in dir(_C)\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             not name.endswith('Base')]\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 64\n",
    "# define a simple linear VAE #until now normal VAE without Beta\n",
    "class LinearVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearVAE, self).__init__()\n",
    " \n",
    "        # encoder 84*84 = 7â€™056\n",
    "        self.enc0 = nn.Linear(in_features=84*84, out_features=1024)\n",
    "        self.enc1 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.enc2 = nn.Linear(in_features=512, out_features=features*2)\n",
    " \n",
    "        # decoder \n",
    "        self.dec0 = nn.Linear(in_features=features, out_features=512)\n",
    "        self.dec1 = nn.Linear(in_features=512, out_features=1024)\n",
    "        self.dec2 = nn.Linear(in_features=1024, out_features=84*84)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
    "        return sample\n",
    " \n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc0(x))\n",
    "        x = F.relu(self.enc1(x))\n",
    "\n",
    "        x = self.enc2(x).view(-1, 2, features)\n",
    "\n",
    "        # get `mu` and `log_var`\n",
    "        mu = x[:, 0, :] # the first feature values as mean\n",
    "        log_var = x[:, 1, :] # the other feature values as variance\n",
    "\n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    " \n",
    "        # decoding\n",
    "        x = F.relu(self.dec0(z))\n",
    "        x = F.relu(self.dec1(x))\n",
    "        reconstruction = torch.sigmoid(self.dec2(x))\n",
    "        return reconstruction, mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b1b2cd",
   "metadata": {},
   "source": [
    "Parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leanring parameters\n",
    "epochs = 10\n",
    "train_games = 100\n",
    "val_games = 20\n",
    "batch_size = 64\n",
    "beta = 10\n",
    "lr = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3660d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_loss(bce_loss, mu, logvar, beta, kl_wheight):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss (BCELoss) and the (one could also take the mse loss instead of bce)\n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param bce_loss: recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    \"\"\"\n",
    "    BCE = bce_loss \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + beta*kl_wheight*KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ddbf3",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50886f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = numpy.load('train_data100kFEB23.npy')\n",
    "val_data = numpy.load('val_data20kFEB23.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ccf97a",
   "metadata": {},
   "source": [
    "Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24375313",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "#get the data randomly\n",
    "total_games = train_games + val_games\n",
    "for o in range(train_games):\n",
    "    print(\"Training Data: In game \"+ str(o) + \" von Total\" + str(total_games))\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = random.choice([2,3])\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        train_data.append(observation[3])\n",
    "\n",
    "        \n",
    "val_data = []\n",
    "#get the data randomly\n",
    "for i in range(val_games):\n",
    "    print(\"Validation Data: In game \"+ str(i) + \" von Total\" + str(total_games))\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = random.choice([2,3])\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        val_data.append(observation[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779145a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffb4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b82d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.save('train_data100kFEB23',train_data,allow_pickle =False)\n",
    "numpy.save('val_data20kFEB23',val_data,allow_pickle =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e3f0c",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1084fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms why do i need a transform?\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ceb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearVAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss(reduction='sum')\n",
    "#criterion = torch.nn.MSELoss(reduction = 'sum')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf229fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "594cc251",
   "metadata": {},
   "source": [
    "Training Loop (we train the autoencoder on one image in the buffer not on the total buffer. This could also be a nice feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7087e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
    "        #data, _ = data\n",
    "        data = data.to(device)\n",
    "        print(data.size)\n",
    "        data = data.view(data.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        reconstruction, mu, logvar = model(data)\n",
    "        bce_loss = criterion(reconstruction, data)\n",
    "        loss = final_loss(bce_loss, mu, logvar, beta, kl_wheight = dataloader.batch_size/len(train_data))\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = running_loss/len(dataloader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30f3c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n",
    "            #data, _ = data\n",
    "            data = data.to(device)\n",
    "            data = data.view(data.size(0), -1)\n",
    "            reconstruction, mu, logvar = model(data)\n",
    "            bce_loss = criterion(reconstruction, data)\n",
    "            loss = final_loss(bce_loss, mu, logvar, beta, kl_wheight = dataloader.batch_size/len(val_data))\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            # save the last batch input and output of every epoch\n",
    "            if i == int(len(val_data)/dataloader.batch_size) - 1:\n",
    "                num_rows = 8\n",
    "                both = torch.cat((data.view(batch_size, 1, 84, 84)[:8], \n",
    "                                  reconstruction.view(batch_size, 1, 84, 84)[:8]))\n",
    "                save_image(both.cpu(), f\"C:/Users/erics/Documents/Programme/Bachelorarbeit/beat_VAE_Pong_runs/run0Beta10/outputBetaFEB25{epoch}.png\", nrow=num_rows)\n",
    "    val_loss = running_loss/len(dataloader.dataset)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eee987c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [00:48, 32.65it/s]                                                                                              \n",
      "328it [00:02, 155.82it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4535.9536\n",
      "Val Loss: 4537.4739\n",
      "Epoch 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [00:50, 31.72it/s]                                                                                              \n",
      "328it [00:02, 157.09it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4535.9164\n",
      "Val Loss: 4537.4564\n",
      "Epoch 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [00:50, 31.44it/s]                                                                                              \n",
      "328it [00:02, 154.73it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4535.8880\n",
      "Val Loss: 4537.2346\n",
      "Epoch 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [00:50, 31.48it/s]                                                                                              \n",
      "328it [00:02, 158.81it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4535.8548\n",
      "Val Loss: 4537.1973\n",
      "Epoch 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:11, 22.16it/s]                                                                                              \n",
      "328it [00:03, 96.33it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4535.8292\n",
      "Val Loss: 4537.3918\n",
      "Epoch 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:07, 23.52it/s]                                                                                              \n",
      "328it [00:02, 121.98it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4535.8032\n",
      "Val Loss: 4537.0784\n",
      "Epoch 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:07, 23.60it/s]                                                                                              \n",
      "328it [00:02, 122.86it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4535.7851\n",
      "Val Loss: 4537.1091\n",
      "Epoch 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:07, 23.61it/s]                                                                                              \n",
      "328it [00:02, 118.54it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4535.7602\n",
      "Val Loss: 4537.0202\n",
      "Epoch 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:21, 19.52it/s]                                                                                              \n",
      "328it [00:03, 91.16it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4535.7415\n",
      "Val Loss: 4536.9943\n",
      "Epoch 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:27, 18.10it/s]                                                                                              \n",
      "328it [00:03, 95.16it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4535.7263\n",
      "Val Loss: 4536.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = fit(model, train_loader)\n",
    "    val_epoch_loss = validate(model, val_loader)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88d8705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'C:/Users/erics/Documents/Programme/Bachelorarbeit/models/BVAE_Pong/B=10VAEFEB25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c71927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
