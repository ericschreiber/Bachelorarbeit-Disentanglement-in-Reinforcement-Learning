{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e58b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym.spaces\n",
    "\n",
    "DEFAULT_ENV_NAME = \"PongNoFrameskip-v4\" \n",
    "test_env = gym.make(DEFAULT_ENV_NAME)\n",
    "print(test_env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9758fd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "print(test_env.unwrapped.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d954b2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9064ea8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 17 10:32:37 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 497.09       Driver Version: 497.09       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P8    N/A /  N/A |     37MiB /  2048MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d43917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc551ea8",
   "metadata": {},
   "source": [
    "# OpenAI Gym Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd6a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from \n",
    "# https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/blob/master/Chapter06/lib/wrappers.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(FireResetEnv, self).__init__(env)\n",
    "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        obs, _, done, _ = self.env.step(1)\n",
    "        if done:\n",
    "            self.env.reset()\n",
    "        obs, _, done, _ = self.env.step(2)\n",
    "        if done:\n",
    "            self.env.reset()\n",
    "        return obs\n",
    "\n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None, skip=4):\n",
    "        super(MaxAndSkipEnv, self).__init__(env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = collections.deque(maxlen=2)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for _ in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            self._obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self._obs_buffer.clear()\n",
    "        obs = self.env.reset()\n",
    "        self._obs_buffer.append(obs)\n",
    "        return obs\n",
    "\n",
    "\n",
    "class ProcessFrame84(gym.ObservationWrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(ProcessFrame84, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return ProcessFrame84.process(obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "        if frame.size == 210 * 160 * 3:\n",
    "            img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
    "        elif frame.size == 250 * 160 * 3:\n",
    "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
    "        else:\n",
    "            assert False, \"Unknown resolution.\"\n",
    "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
    "        x_t = resized_screen[18:102, :]\n",
    "        x_t = np.reshape(x_t, [84, 84, 1])\n",
    "        return x_t.astype(np.uint8)\n",
    "\n",
    "\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_steps, dtype=np.float32):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.dtype = dtype\n",
    "        old_space = env.observation_space\n",
    "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
    "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
    "        return self.observation(self.env.reset())\n",
    "\n",
    "    def observation(self, observation):\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1] = observation\n",
    "        return self.buffer\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], \n",
    "                                old_shape[0], old_shape[1]), dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "def make_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = FireResetEnv(env)\n",
    "    env = ProcessFrame84(env)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env = BufferWrapper(env, 4)\n",
    "    return ScaledFloatFrame(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e912c9",
   "metadata": {},
   "source": [
    "## The DQN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94159942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn        # Pytorch neural network package\n",
    "import torch.optim as optim  # Pytorch optimization package\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f34e72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from \n",
    "# https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/blob/master/Chapter06/lib/dqn_model.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc(conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2d17a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "(4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "test_env = make_env(DEFAULT_ENV_NAME)\n",
    "test_net = DQN(test_env.observation_space.shape, test_env.action_space.n).to(device)\n",
    "print(test_net)\n",
    "print(test_env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f63cad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model=r'C:\\Users\\erics\\Documents\\Programme\\Bachelorarbeit\\PongNoFrameskip-v4-best-Kopie-11-300.dat'\n",
    "model=r'C:\\Users\\erics\\Documents\\Programme\\RL_Beispiel_Projekt\\PongNoFrameskip-v4-best.dat'\n",
    "test_net.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604feba5",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42050142",
   "metadata": {},
   "source": [
    "Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07bb7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = collections.namedtuple('Experience', field_names=['state', 'action', 'reward', 'done', 'new_state'])\n",
    "\n",
    "class ExperienceReplay:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def append(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        states, actions, rewards, dones, next_states = zip(*[self.buffer[idx] for idx in indices])\n",
    "        return np.array(states), np.array(actions), np.array(rewards, dtype=np.float32), \\\n",
    "               np.array(dones, dtype=np.uint8), np.array(next_states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90b318",
   "metadata": {},
   "source": [
    "Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6ad8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env, exp_buffer):\n",
    "        self.env = env\n",
    "        self.exp_buffer = exp_buffer\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        self.state = env.reset()\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    def play_step(self, net, epsilon=0.0, device=\"cpu\"):\n",
    "        \n",
    "        if VISUALIZEtraining:\n",
    "            env.render()\n",
    "            \n",
    "        done_reward = None\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            state_a = np.array([self.state], copy=False)\n",
    "            state_v = torch.tensor(state_a).to(device)\n",
    "            q_vals_v = net(state_v)\n",
    "            _, act_v = torch.max(q_vals_v, dim=1)\n",
    "            action = int(act_v.item())\n",
    "\n",
    "        new_state, reward, is_done, _ = self.env.step(action)\n",
    "        self.total_reward += reward\n",
    "\n",
    "        exp = Experience(self.state, action, reward, is_done, new_state)\n",
    "        self.exp_buffer.append(exp)\n",
    "        self.state = new_state\n",
    "        if is_done:\n",
    "            done_reward = self.total_reward\n",
    "            self._reset()\n",
    "        return done_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b928bf7",
   "metadata": {},
   "source": [
    "Data Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "768069fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_games = 3\n",
    "val_games = 0\n",
    "visualize = True\n",
    "train_data = []\n",
    "total_games = train_games + val_games\n",
    "env2 = make_env(DEFAULT_ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2252592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: In game 0 von Total3\n",
      "Training Data: In game 1 von Total3\n",
      "Training Data: In game 2 von Total3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for o in range(train_games):\n",
    "    print(\"Training Data: In game \"+ str(o) + \" von Total\" + str(total_games))\n",
    "    state = test_env.reset()\n",
    "    state = env2.reset()\n",
    "    \n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        if visualize:\n",
    "            env2.render()\n",
    "        state_v = torch.tensor(np.array([state], copy=False)).to(device)\n",
    "        q_vals = test_net(state_v).data.detach().cpu().numpy()[0]\n",
    "        action = np.argmax(q_vals)\n",
    "        \n",
    "        state, reward, done, _ = env2.step(action)\n",
    "        \n",
    "        train_data.append(state[3])\n",
    "\n",
    "        \n",
    "val_data = []\n",
    "#get the data randomly\n",
    "for i in range(val_games):\n",
    "    print(\"Validation Data: In game \"+ str(i) + \" von Total\" + str(total_games))\n",
    "\n",
    "    state = test_env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        if visualize:\n",
    "            env2.render()\n",
    "            \n",
    "        state_v = torch.tensor(np.array([state], copy=False)).to(device)\n",
    "        q_vals = test_net(state_v).data.numpy()[0]\n",
    "        action = np.argmax(q_vals)\n",
    "        \n",
    "        state, reward, done, _ = env2.step(action)\n",
    "        \n",
    "        val_data.append(state[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c9a3889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6141\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(len(train_data))\n",
    "plt.imshow(train_data[170])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b646ddf",
   "metadata": {},
   "source": [
    "#ToDo: Trainiere DQN bis 0 oder 3h merke bestes Netz @-19, -17, -13, -11, .... Speichere anfangsseeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6176383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
