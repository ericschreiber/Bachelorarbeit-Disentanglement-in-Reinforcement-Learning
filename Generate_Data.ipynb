{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e58b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym.spaces\n",
    "\n",
    "DEFAULT_ENV_NAME = \"PongNoFrameskip-v4\" \n",
    "test_env = gym.make(DEFAULT_ENV_NAME)\n",
    "print(test_env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9758fd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "print(test_env.unwrapped.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d954b2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9064ea8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 28 14:41:36 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 497.09       Driver Version: 497.09       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P5    N/A /  N/A |   1902MiB /  2048MiB |     95%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      5508      C   ...envs\\PyTorchRL\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     11872      C   ...envs\\PyTorchRL\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d43917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc551ea8",
   "metadata": {},
   "source": [
    "# OpenAI Gym Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cdd6a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from \n",
    "# https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/blob/master/Chapter06/lib/wrappers.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(FireResetEnv, self).__init__(env)\n",
    "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        obs, _, done, _ = self.env.step(1)\n",
    "        if done:\n",
    "            self.env.reset()\n",
    "        obs, _, done, _ = self.env.step(2)\n",
    "        if done:\n",
    "            self.env.reset()\n",
    "        return obs\n",
    "\n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None, skip=4):\n",
    "        super(MaxAndSkipEnv, self).__init__(env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = collections.deque(maxlen=2)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for _ in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            self._obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self._obs_buffer.clear()\n",
    "        obs = self.env.reset()\n",
    "        self._obs_buffer.append(obs)\n",
    "        return obs\n",
    "\n",
    "\n",
    "class ProcessFrame84(gym.ObservationWrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(ProcessFrame84, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return ProcessFrame84.process(obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "        if frame.size == 210 * 160 * 3:\n",
    "            img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
    "        elif frame.size == 250 * 160 * 3:\n",
    "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
    "        else:\n",
    "            assert False, \"Unknown resolution.\"\n",
    "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
    "        x_t = resized_screen[18:102, :]\n",
    "        x_t = np.reshape(x_t, [84, 84, 1])\n",
    "        return x_t.astype(np.uint8)\n",
    "\n",
    "\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_steps, dtype=np.float32):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.dtype = dtype\n",
    "        old_space = env.observation_space\n",
    "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
    "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
    "        return self.observation(self.env.reset())\n",
    "\n",
    "    def observation(self, observation):\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1] = observation\n",
    "        return self.buffer\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], \n",
    "                                old_shape[0], old_shape[1]), dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "    \n",
    "class Scale01(gym.ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        obs[obs < 0.342] = 0\n",
    "        obs[:, 83, :] = 0 #unterste pixelreihe war immer 1 also hat keine Infos. Daher wird auf 0 gesetzt.\n",
    "        obs[obs > 0.1] = 1\n",
    "        return obs\n",
    "\n",
    "def make_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = FireResetEnv(env)\n",
    "    env = ProcessFrame84(env)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env = BufferWrapper(env, 4)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    return Scale01(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e912c9",
   "metadata": {},
   "source": [
    "## The DQN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "94159942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn        # Pytorch neural network package\n",
    "import torch.optim as optim  # Pytorch optimization package\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f34e72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from \n",
    "# https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/blob/master/Chapter06/lib/dqn_model.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc(conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3c2d17a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "(4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "test_env = make_env(DEFAULT_ENV_NAME)\n",
    "test_net = DQN(test_env.observation_space.shape, test_env.action_space.n).to(device)\n",
    "print(test_net)\n",
    "print(test_env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f63cad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model=r'C:\\Users\\erics\\Documents\\Programme\\Bachelorarbeit\\PongNoFrameskip-v4-best-Kopie-11-300.dat'\n",
    "model=r'C:\\Users\\erics\\Documents\\Programme\\RL_Beispiel_Projekt\\PongNoFrameskip-v4-best.dat'\n",
    "test_net.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604feba5",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42050142",
   "metadata": {},
   "source": [
    "Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07bb7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = collections.namedtuple('Experience', field_names=['state', 'action', 'reward', 'done', 'new_state'])\n",
    "\n",
    "class ExperienceReplay:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def append(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        states, actions, rewards, dones, next_states = zip(*[self.buffer[idx] for idx in indices])\n",
    "        return np.array(states), np.array(actions), np.array(rewards, dtype=np.float32), \\\n",
    "               np.array(dones, dtype=np.uint8), np.array(next_states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90b318",
   "metadata": {},
   "source": [
    "Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bb6ad8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env, exp_buffer):\n",
    "        self.env = env\n",
    "        self.exp_buffer = exp_buffer\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        self.state = env.reset()\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    def play_step(self, net, epsilon=0.0, device=\"cpu\"):\n",
    "        \n",
    "        if VISUALIZEtraining:\n",
    "            env.render()\n",
    "            \n",
    "        done_reward = None\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            state_a = np.array([self.state], copy=False)\n",
    "            state_v = torch.tensor(state_a).to(device)\n",
    "            q_vals_v = net(state_v)\n",
    "            _, act_v = torch.max(q_vals_v, dim=1)\n",
    "            action = int(act_v.item())\n",
    "\n",
    "        new_state, reward, is_done, _ = self.env.step(action)\n",
    "        self.total_reward += reward\n",
    "\n",
    "        exp = Experience(self.state, action, reward, is_done, new_state)\n",
    "        self.exp_buffer.append(exp)\n",
    "        self.state = new_state\n",
    "        if is_done:\n",
    "            done_reward = self.total_reward\n",
    "            self._reset()\n",
    "        return done_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b928bf7",
   "metadata": {},
   "source": [
    "Data Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "768069fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_games = 1\n",
    "val_games = 0\n",
    "visualize = False\n",
    "train_data = []\n",
    "total_games = train_games + val_games\n",
    "env2 = make_env(DEFAULT_ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2252592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: In game 0 von Total1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for o in range(train_games):\n",
    "    print(\"Training Data: In game \"+ str(o) + \" von Total\" + str(total_games))\n",
    "    state = test_env.reset()\n",
    "    state = env2.reset()\n",
    "    \n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        if visualize:\n",
    "            env2.render()\n",
    "        state_v = torch.tensor(np.array([state], copy=False)).to(device)\n",
    "        q_vals = test_net(state_v).data.detach().cpu().numpy()[0]\n",
    "        action = np.argmax(q_vals)\n",
    "        \n",
    "        state, reward, done, _ = env2.step(action)\n",
    "        \n",
    "        train_data.append(state[3])\n",
    "\n",
    "        \n",
    "val_data = []\n",
    "#get the data randomly\n",
    "for i in range(val_games):\n",
    "    print(\"Validation Data: In game \"+ str(i) + \" von Total\" + str(total_games))\n",
    "\n",
    "    state = test_env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        if visualize:\n",
    "            env2.render()\n",
    "            \n",
    "        state_v = torch.tensor(np.array([state], copy=False)).to(device)\n",
    "        q_vals = test_net(state_v).data.numpy()[0]\n",
    "        action = np.argmax(q_vals)\n",
    "        \n",
    "        state, reward, done, _ = env2.step(action)\n",
    "        \n",
    "        val_data.append(state[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c9a3889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3034\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGgCAYAAAAD9NhnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfeklEQVR4nO3df2yV5f3/8deRwqHF9myinNMzCxy241ALE0E7C7HdtF2QEEw3pxQVQ7KABaWSWah1sxI51W5rutmJgxiswQ6zDIW5qa06qqZjlG5VVgxo7KBTzjpdd06VrgV6ff/wy/3hWNSd/vDilOcjuRN739dp371CfOZuzzl1GWOMAACw4BzbAwAAzl5ECABgDRECAFhDhAAA1hAhAIA1RAgAYA0RAgBYQ4QAANYQIQCANUQIAGDNiEXokUceUSAQ0Pjx4zV79my9+uqrI/WlAAAJKmkkPulTTz2l4uJiPfLII5o7d65+9atfaf78+dq/f78mT578mY/t7+/Xe++9p9TUVLlcrpEYDwAwgowx6u7ult/v1znnfM69jhkBV155pVmxYkXMuenTp5t169Z97mM7OjqMJA4ODg6OBD86Ojo+9//5w34n1NfXp5aWFq1bty7mfH5+vpqamgas7+3tVW9vr/Ox+f9v6j1P1ylJY4d7PADACDuuY3pNf1Bqaurnrh32CL3//vs6ceKEvF5vzHmv16twODxgfUVFhe6///7TDDZWSS4iBAAJ5+N7if/pVyoj9sSET35xY8xpByotLVUkEnGOjo6OkRoJAHCGGfY7ofPPP19jxowZcNfT2dk54O5Iktxut9xu93CPAQBIAMN+JzRu3DjNnj1bDQ0NMecbGhqUnZ093F8OAJDARuQp2mvWrNEtt9yiOXPm6KqrrtKmTZt0+PBhrVixYiS+HAAgQY1IhG688UZ98MEHWr9+vY4cOaLMzEz94Q9/0JQpU0biywEAEpTLnHxO9BkiGo3K4/EoV4t4dhwAJKDj5ph2aYcikYjS0tI+cy3vHQcAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwJu4IvfLKK1q4cKH8fr9cLpeeeeaZmOvGGJWXl8vv9ys5OVm5ublqa2sbrnkBAKNI3BH66KOP9I1vfEM1NTWnvV5ZWamqqirV1NSoublZPp9PeXl56u7uHvKwAIDRJSneB8yfP1/z588/7TVjjKqrq1VWVqaCggJJUm1trbxer+rq6rR8+fKhTQsAGFWG9XdC7e3tCofDys/Pd8653W7l5OSoqanptI/p7e1VNBqNOQAAZ4dhjVA4HJYkeb3emPNer9e59kkVFRXyeDzOkZGRMZwjAQDOYCPy7DiXyxXzsTFmwLmTSktLFYlEnKOjo2MkRgIAnIHi/p3QZ/H5fJI+viNKT093znd2dg64OzrJ7XbL7XYP5xgAgAQxrHdCgUBAPp9PDQ0Nzrm+vj41NjYqOzt7OL8UAGAUiPtO6MMPP9Tbb7/tfNze3q7W1ladd955mjx5soqLixUKhRQMBhUMBhUKhZSSkqLCwsJhHRwAkPjijtDevXv1rW99y/l4zZo1kqSlS5fq8ccfV0lJiXp6elRUVKSuri5lZWWpvr5eqampwzc1AGBUcBljjO0hThWNRuXxeJSrRUpyjbU9DgAgTsfNMe3SDkUiEaWlpX3mWt47DgBgDRECAFhDhAAA1hAhAIA1RAgAYA0RAgBYQ4QAANYQIQCANUQIAGANEQIAWEOEAADWECEAgDVECABgDRECAFhDhAAA1hAhAIA1RAgAYA0RAgBYQ4QAANYQIQCANUQIAGANEQIAWEOEAADWECEAgDVECABgDRECAFhDhAAA1hAhAIA1RAgAYA0RAgBYQ4QAANYQIQCANUQIAGBNXBGqqKjQFVdcodTUVE2aNEnXX3+9Dhw4ELPGGKPy8nL5/X4lJycrNzdXbW1twzo0AGB0iCtCjY2NWrlypXbv3q2GhgYdP35c+fn5+uijj5w1lZWVqqqqUk1NjZqbm+Xz+ZSXl6fu7u5hHx4AkNhcxhgz2Af/61//0qRJk9TY2Kirr75axhj5/X4VFxdr7dq1kqTe3l55vV499NBDWr58+ed+zmg0Ko/Ho1wtUpJr7GBHAwBYctwc0y7tUCQSUVpa2meuHdLvhCKRiCTpvPPOkyS1t7crHA4rPz/fWeN2u5WTk6OmpqbTfo7e3l5Fo9GYAwBwdhh0hIwxWrNmjebNm6fMzExJUjgcliR5vd6YtV6v17n2SRUVFfJ4PM6RkZEx2JEAAAlm0BFatWqV3njjDf36178ecM3lcsV8bIwZcO6k0tJSRSIR5+jo6BjsSACABJM0mAfdcccd2rlzp1555RVdeOGFznmfzyfp4zui9PR053xnZ+eAu6OT3G633G73YMYAACS4uO6EjDFatWqVtm/frpdfflmBQCDmeiAQkM/nU0NDg3Our69PjY2Nys7OHp6JAQCjRlx3QitXrlRdXZ127Nih1NRU5/c8Ho9HycnJcrlcKi4uVigUUjAYVDAYVCgUUkpKigoLC0fkGwAAJK64IrRx40ZJUm5ubsz5LVu26LbbbpMklZSUqKenR0VFRerq6lJWVpbq6+uVmpo6LAMDAEaPIb1OaCTwOiEASGxf2OuEAAAYCiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwJsn2AACAgV54rzXux3zHf9mwzzHSuBMCAFhDhAAA1sQVoY0bN2rmzJlKS0tTWlqarrrqKj333HPOdWOMysvL5ff7lZycrNzcXLW1tQ370ACA0SGuCF144YV68MEHtXfvXu3du1ff/va3tWjRIic0lZWVqqqqUk1NjZqbm+Xz+ZSXl6fu7u4RGR4AkNjiitDChQt13XXX6aKLLtJFF12kDRs26Nxzz9Xu3btljFF1dbXKyspUUFCgzMxM1dbW6ujRo6qrqxup+QEACWzQvxM6ceKEtm3bpo8++khXXXWV2tvbFQ6HlZ+f76xxu93KyclRU1PTp36e3t5eRaPRmAMAcHaIO0L79u3TueeeK7fbrRUrVujpp5/WJZdconA4LEnyer0x671er3PtdCoqKuTxeJwjIyMj3pEAAAkq7gh9/etfV2trq3bv3q3bb79dS5cu1f79+53rLpcrZr0xZsC5U5WWlioSiThHR0dHvCMBABJU3C9WHTdunL72ta9JkubMmaPm5mb9/Oc/19q1ayVJ4XBY6enpzvrOzs4Bd0encrvdcrvd8Y4BABgFhvw6IWOMent7FQgE5PP51NDQ4Fzr6+tTY2OjsrOzh/plAACjUFx3Qvfcc4/mz5+vjIwMdXd3a9u2bdq1a5eef/55uVwuFRcXKxQKKRgMKhgMKhQKKSUlRYWFhSM1PwAggcUVoX/+85+65ZZbdOTIEXk8Hs2cOVPPP/+88vLyJEklJSXq6elRUVGRurq6lJWVpfr6eqWmpo7I8ACAxOYyxhjbQ5wqGo3K4/EoV4uU5BprexwAsCKR38D0uDmmXdqhSCSitLS0z1zLe8cBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArBlShCoqKuRyuVRcXOycM8aovLxcfr9fycnJys3NVVtb21DnBACMQkmDfWBzc7M2bdqkmTNnxpyvrKxUVVWVHn/8cV100UV64IEHlJeXpwMHDig1NXXIAwPA2eA7/stsj/CFGNSd0IcffqglS5Zo8+bN+vKXv+ycN8aourpaZWVlKigoUGZmpmpra3X06FHV1dUN29AAgNFhUBFauXKlFixYoGuvvTbmfHt7u8LhsPLz851zbrdbOTk5ampqOu3n6u3tVTQajTkAAGeHuH8ct23bNrW0tGjv3r0DroXDYUmS1+uNOe/1enXo0KHTfr6Kigrdf//98Y4BABgF4roT6ujo0OrVq/Xkk09q/Pjxn7rO5XLFfGyMGXDupNLSUkUiEefo6OiIZyQAQAKL606opaVFnZ2dmj17tnPuxIkTeuWVV1RTU6MDBw5I+viOKD093VnT2dk54O7oJLfbLbfbPZjZAQAJLq47oWuuuUb79u1Ta2urc8yZM0dLlixRa2urpk2bJp/Pp4aGBucxfX19amxsVHZ29rAPDwBIbHHdCaWmpiozMzPm3IQJEzRx4kTnfHFxsUKhkILBoILBoEKhkFJSUlRYWDh8UwMARoVBv07o05SUlKinp0dFRUXq6upSVlaW6uvreY0QAGAAlzHG2B7iVNFoVB6PR7lapCTXWNvjAADidNwc0y7tUCQSUVpa2meu5b3jAADWECEAgDVECABgDRECAFhDhAAA1hAhAIA1RAgAYA0RAgBYQ4QAANYQIQCANUQIAGANEQIAWEOEAADWECEAgDVECABgDRECAFhDhAAA1hAhAIA1RAgAYA0RAgBYQ4QAANYQIQCANUQIAGANEQIAWEOEAADWECEAgDVECABgDRECAFhDhAAA1hAhAIA1RAgAYA0RAgBYQ4QAANbEFaHy8nK5XK6Yw+fzOdeNMSovL5ff71dycrJyc3PV1tY27EMDAEaHuO+ELr30Uh05csQ59u3b51yrrKxUVVWVampq1NzcLJ/Pp7y8PHV3dw/r0ACA0SHuCCUlJcnn8znHBRdcIOnju6Dq6mqVlZWpoKBAmZmZqq2t1dGjR1VXVzfsgwMAEl/cEXrrrbfk9/sVCAR000036Z133pEktbe3KxwOKz8/31nrdruVk5OjpqamT/18vb29ikajMQcA4OwQV4SysrL0xBNP6IUXXtDmzZsVDoeVnZ2tDz74QOFwWJLk9XpjHuP1ep1rp1NRUSGPx+McGRkZg/g2AACJKK4IzZ8/X9/97nc1Y8YMXXvttfr9738vSaqtrXXWuFyumMcYYwacO1VpaakikYhzdHR0xDMSACCBDekp2hMmTNCMGTP01ltvOc+S++RdT2dn54C7o1O53W6lpaXFHACAs8OQItTb26s333xT6enpCgQC8vl8amhocK739fWpsbFR2dnZQx4UADD6JMWz+Ic//KEWLlyoyZMnq7OzUw888ICi0aiWLl0ql8ul4uJihUIhBYNBBYNBhUIhpaSkqLCwcKTmBwAksLgi9I9//EOLFy/W+++/rwsuuEDf/OY3tXv3bk2ZMkWSVFJSop6eHhUVFamrq0tZWVmqr69XamrqiAwPAEhsLmOMsT3EqaLRqDwej3K1SEmusbbHAQDE6bg5pl3aoUgk8rm/5+e94wAA1hAhAIA1RAgAYA0RAgBYQ4QAANYQIQCANUQIAGANEQIAWEOEAADWECEAgDVECABgDRECAFhDhAAA1hAhAIA1RAgAYA0RAgBYQ4QAANYQIQCANUQIAGANEQIAWEOEAADWECEAgDVECABgDRECAFhDhAAA1hAhAIA1RAgAYA0RAgBYQ4QAANYQIQCANUQIAGANEQIAWEOEAADWxB2hd999VzfffLMmTpyolJQUXXbZZWppaXGuG2NUXl4uv9+v5ORk5ebmqq2tbViHBgCMDnFFqKurS3PnztXYsWP13HPPaf/+/frZz36mL33pS86ayspKVVVVqaamRs3NzfL5fMrLy1N3d/dwzw4ASHBJ8Sx+6KGHlJGRoS1btjjnpk6d6vy3MUbV1dUqKytTQUGBJKm2tlZer1d1dXVavnz58EwNABgV4roT2rlzp+bMmaMbbrhBkyZN0qxZs7R582bnent7u8LhsPLz851zbrdbOTk5ampqOu3n7O3tVTQajTkAAGeHuCL0zjvvaOPGjQoGg3rhhRe0YsUK3XnnnXriiSckSeFwWJLk9XpjHuf1ep1rn1RRUSGPx+McGRkZg/k+AAAJKK4I9ff36/LLL1coFNKsWbO0fPly/eAHP9DGjRtj1rlcrpiPjTEDzp1UWlqqSCTiHB0dHXF+CwCARBVXhNLT03XJJZfEnLv44ot1+PBhSZLP55OkAXc9nZ2dA+6OTnK73UpLS4s5AABnh7giNHfuXB04cCDm3MGDBzVlyhRJUiAQkM/nU0NDg3O9r69PjY2Nys7OHoZxAQCjSVzPjrvrrruUnZ2tUCik73//+9qzZ482bdqkTZs2Sfr4x3DFxcUKhUIKBoMKBoMKhUJKSUlRYWHhiHwDAIDEFVeErrjiCj399NMqLS3V+vXrFQgEVF1drSVLljhrSkpK1NPTo6KiInV1dSkrK0v19fVKTU0d9uEBAInNZYwxtoc4VTQalcfjUa4WKck11vY4AIA4HTfHtEs7FIlEPvf3/Lx3HADAGiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMCauCI0depUuVyuAcfKlSslScYYlZeXy+/3Kzk5Wbm5uWpraxuRwQEAiS+uCDU3N+vIkSPO0dDQIEm64YYbJEmVlZWqqqpSTU2Nmpub5fP5lJeXp+7u7uGfHACQ8OKK0AUXXCCfz+cczz77rL761a8qJydHxhhVV1errKxMBQUFyszMVG1trY4ePaq6urqRmh8AkMAG/Tuhvr4+bd26VcuWLZPL5VJ7e7vC4bDy8/OdNW63Wzk5OWpqavrUz9Pb26toNBpzAADODoOO0DPPPKP//Oc/uu222yRJ4XBYkuT1emPWeb1e59rpVFRUyOPxOEdGRsZgRwIAJJhBR+ixxx7T/Pnz5ff7Y867XK6Yj40xA86dqrS0VJFIxDk6OjoGOxIAIMEkDeZBhw4d0osvvqjt27c753w+n6SP74jS09Od852dnQPujk7ldrvldrsHMwYAIMEN6k5oy5YtmjRpkhYsWOCcCwQC8vl8zjPmpI9/b9TY2Kjs7OyhTwoAGHXivhPq7+/Xli1btHTpUiUl/d/DXS6XiouLFQqFFAwGFQwGFQqFlJKSosLCwmEdGgAwOsQdoRdffFGHDx/WsmXLBlwrKSlRT0+PioqK1NXVpaysLNXX1ys1NXVYhgUAjC4uY4yxPcSpotGoPB6PcrVISa6xtscBAMTpuDmmXdqhSCSitLS0z1zLe8cBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGuIEADAGiIEALCGCAEArIkrQsePH9e9996rQCCg5ORkTZs2TevXr1d/f7+zxhij8vJy+f1+JScnKzc3V21tbcM+OAAg8cUVoYceekiPPvqoampq9Oabb6qyslI/+clP9PDDDztrKisrVVVVpZqaGjU3N8vn8ykvL0/d3d3DPjwAILHFFaE//elPWrRokRYsWKCpU6fqe9/7nvLz87V3715JH98FVVdXq6ysTAUFBcrMzFRtba2OHj2qurq6EfkGAACJK64IzZs3Ty+99JIOHjwoSXr99df12muv6brrrpMktbe3KxwOKz8/33mM2+1WTk6OmpqaTvs5e3t7FY1GYw4AwNkhKZ7Fa9euVSQS0fTp0zVmzBidOHFCGzZs0OLFiyVJ4XBYkuT1emMe5/V6dejQodN+zoqKCt1///2DmR0AkODiuhN66qmntHXrVtXV1ekvf/mLamtr9dOf/lS1tbUx61wuV8zHxpgB504qLS1VJBJxjo6Ojji/BQBAoorrTujuu+/WunXrdNNNN0mSZsyYoUOHDqmiokJLly6Vz+eT9PEdUXp6uvO4zs7OAXdHJ7ndbrnd7sHODwBIYHHdCR09elTnnBP7kDFjxjhP0Q4EAvL5fGpoaHCu9/X1qbGxUdnZ2cMwLgBgNInrTmjhwoXasGGDJk+erEsvvVR//etfVVVVpWXLlkn6+MdwxcXFCoVCCgaDCgaDCoVCSklJUWFh4Yh8AwCAxBVXhB5++GH96Ec/UlFRkTo7O+X3+7V8+XL9+Mc/dtaUlJSop6dHRUVF6urqUlZWlurr65WamjrswwMAEpvLGGNsD3GqaDQqj8ejXC1Skmus7XEAAHE6bo5pl3YoEokoLS3tM9fy3nEAAGuIEADAGiIEALCGCAEArCFCAABriBAAwBoiBACwJq4Xq34RTr5s6biOSWfUK5gAAP+L4zom6f/+f/5ZzrgInfwLrK/pD5YnAQAMRXd3tzwez2euOePeMaG/v1/vvfeeUlNT1d3drYyMDHV0dHzuq24Rv2g0yv6OIPZ3ZLG/I2so+2uMUXd3t/x+/4A3vf6kM+5O6JxzztGFF14o6f/+LlFaWhr/yEYQ+zuy2N+Rxf6OrMHu7+fdAZ3EExMAANYQIQCANWd0hNxut+677z7+8uoIYX9HFvs7stjfkfVF7e8Z98QEAMDZ44y+EwIAjG5ECABgDRECAFhDhAAA1hAhAIA1Z2yEHnnkEQUCAY0fP16zZ8/Wq6++anukhFRRUaErrrhCqampmjRpkq6//nodOHAgZo0xRuXl5fL7/UpOTlZubq7a2tosTZy4Kioq5HK5VFxc7Jxjb4fu3Xff1c0336yJEycqJSVFl112mVpaWpzr7PHgHT9+XPfee68CgYCSk5M1bdo0rV+/Xv39/c6aEd9fcwbatm2bGTt2rNm8ebPZv3+/Wb16tZkwYYI5dOiQ7dESzne+8x2zZcsW87e//c20traaBQsWmMmTJ5sPP/zQWfPggw+a1NRU89vf/tbs27fP3HjjjSY9Pd1Eo1GLkyeWPXv2mKlTp5qZM2ea1atXO+fZ26H597//baZMmWJuu+028+c//9m0t7ebF1980bz99tvOGvZ48B544AEzceJE8+yzz5r29nbzm9/8xpx77rmmurraWTPS+3tGRujKK680K1asiDk3ffp0s27dOksTjR6dnZ1GkmlsbDTGGNPf3298Pp958MEHnTX//e9/jcfjMY8++qitMRNKd3e3CQaDpqGhweTk5DgRYm+Hbu3atWbevHmfep09HpoFCxaYZcuWxZwrKCgwN998szHmi9nfM+7HcX19fWppaVF+fn7M+fz8fDU1NVmaavSIRCKSpPPOO0+S1N7ernA4HLPfbrdbOTk57Pf/aOXKlVqwYIGuvfbamPPs7dDt3LlTc+bM0Q033KBJkyZp1qxZ2rx5s3OdPR6aefPm6aWXXtLBgwclSa+//rpee+01XXfddZK+mP09495F+/3339eJEyfk9Xpjznu9XoXDYUtTjQ7GGK1Zs0bz5s1TZmamJDl7err9PnTo0Bc+Y6LZtm2bWlpatHfv3gHX2Nuhe+edd7Rx40atWbNG99xzj/bs2aM777xTbrdbt956K3s8RGvXrlUkEtH06dM1ZswYnThxQhs2bNDixYslfTH/hs+4CJ108s84nGSMGXAO8Vm1apXeeOMNvfbaawOusd/x6+jo0OrVq1VfX6/x48d/6jr2dvD6+/s1Z84chUIhSdKsWbPU1tamjRs36tZbb3XWsceD89RTT2nr1q2qq6vTpZdeqtbWVhUXF8vv92vp0qXOupHc3zPux3Hnn3++xowZM+Cup7Ozc0CN8b+74447tHPnTv3xj390/l6TJPl8PklivwehpaVFnZ2dmj17tpKSkpSUlKTGxkb94he/UFJSkrN/7O3gpaen65JLLok5d/HFF+vw4cOS+Pc7VHfffbfWrVunm266STNmzNAtt9yiu+66SxUVFZK+mP094yI0btw4zZ49Ww0NDTHnGxoalJ2dbWmqxGWM0apVq7R9+3a9/PLLCgQCMdcDgYB8Pl/Mfvf19amxsZH9/hzXXHON9u3bp9bWVueYM2eOlixZotbWVk2bNo29HaK5c+cOeEnBwYMHNWXKFEn8+x2qo0ePDvjLp2PGjHGeov2F7O+wPL1hmJ18ivZjjz1m9u/fb4qLi82ECRPM3//+d9ujJZzbb7/deDwes2vXLnPkyBHnOHr0qLPmwQcfNB6Px2zfvt3s27fPLF68mKe4DtKpz44zhr0dqj179pikpCSzYcMG89Zbb5knn3zSpKSkmK1btzpr2OPBW7p0qfnKV77iPEV7+/bt5vzzzzclJSXOmpHe3zMyQsYY88tf/tJMmTLFjBs3zlx++eXOU4oRH0mnPbZs2eKs6e/vN/fdd5/x+XzG7Xabq6++2uzbt8/e0AnskxFib4fud7/7ncnMzDRut9tMnz7dbNq0KeY6ezx40WjUrF692kyePNmMHz/eTJs2zZSVlZne3l5nzUjvL39PCABgzRn3OyEAwNmDCAEArCFCAABriBAAwBoiBACwhggBAKwhQgAAa4gQAMAaIgQAsIYIAQCsIUIAAGv+H0IQaagJfBHjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(len(train_data))\n",
    "plt.imshow(train_data[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c6176383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd35500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
