Untersuchen was besser sein könnte:
	schnellere Trainingtimes (mehr Bilder pro Sekunde)  	
	schnellere Konvergenz	(schneller gutes Resultat) (Hauptanalyse)
	Besserer Start
	kleineres Model 	(weniger Speicher & schnellere Ausführungszeit) (Agent verkleinern evt)
	bessere Schlussergebnisse nach langem Training

Wie könnte man dies Messen:
	1., 2. 10 verschiedene Trainingsruns bis Loss = 0 (equal wins and fails)
	3. latent space untersuchen, model wheight messen wie gut lässt sichs prunen(1) Unterschiedliche grosse modele Trainieren (2)
	4. 5 Trainingsruns für X Stunden (bsp 10 h ~2 Tage)
	
Loggen:
	Performance per step (How long does one step take and where the bottleneck is)[Torch Profiler]
	increase in reward per step [Tensorboard]
	Mean reward [Tensorboard]
	
Verändern:
	Random Seeds
	Epsilon
	Beta & Tc
	Networks
	

VAE:
1. Untersuchen auf 1 Bild reconstruction (all linear & conv & groundtruth factors[mittelpunkt des balls etc] (netuwerk trainiern auf GT labels))
2. Trainieren auf besten Hyperparameter für conv mit 4 chanel inputs
Untersuchen was besser sein könnte:
	schnellere Trainingtimes (mehr Bilder pro Sekunde)  	
	schnellere Konvergenz	(schneller gutes Resultat)
	kleineres Model 	(weniger Speicher & schnellere Ausführungszeit) 
	bessere Schlussergebnisse nach langem Training
	bessere Dientanglement

Wie könnte man dies Messen:
	1., 2. 10 verschiedene Trainingsruns 10 Epochs
	3. latent space untersuchen, model wheight messen wie gut lässt sichs prunen(1) Unterschiedliche grosse modele Trainieren (2)
	4. 5 Trainingsruns für X Stunden (bsp 30 Epochs)
	****5. Disentanglement metrics***
Loggen:
	Performance per step (How long does one step take and where the bottleneck is)[Torch Profiler]
	decrease in loss per step [Tensorboard]
	Epochs [Tensorboard]
	
Verändern:
	Random Seeds
	Epsilon
	Beta & Tc
	Networks {linear 1, 2, 3, 4, Conv like DQN, Conv like Bestermann}
			