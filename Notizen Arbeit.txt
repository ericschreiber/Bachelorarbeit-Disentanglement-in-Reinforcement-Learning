Variational autoencoder können genutzt werden um Information zu komprimieren. Es wurde gezeigt, dass man mit einer korrekten Regularisierung die repräsentation in den latent variables dazu bringen kann einzelne Features voneinander zu disentanglen und dies sich ähnlich zu einer PCA Analyse verhält[1]. Da somit wenig bis im besten Fall keine Information verloren geht kann man, solange die Trainings- und die Aufgabendaten die gleiche Verteilung haben, diese repräsentationen auch zur vereinfachung von einer nachgelagerten Aufgabe nutzen[2]. 
Ein Problem bei reinforcement learning ist, dass man oft sehr viele Inputvariablen hat, welche nicht unabhängig voneinander sind. Können wir diese Inputdaten zuerst transformieren zu wenigen unabhängigen features bräuchte man ein kleineres Netz was zu weniger benötigten Speicherplatz im Training sowie im Deployment, weniger Rechenaufwand sowie zu einer schnelleren Konvergenz am Anfang und möglicherweise sogar einem besseren Endergebnis führen kann.
