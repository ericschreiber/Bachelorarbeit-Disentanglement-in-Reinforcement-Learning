{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06f2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchtyping import TensorType\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d02a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 16\n",
    "# define a simple linear VAE #until now normal VAE without Beta\n",
    "class LinearVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearVAE, self).__init__()\n",
    " \n",
    "        # encoder 84*84 = 7â€™056\n",
    "        self.enc0 = nn.Linear(in_features=84*84, out_features=1024)\n",
    "        self.enc1 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.enc2 = nn.Linear(in_features=512, out_features=features*2)\n",
    " \n",
    "        # decoder \n",
    "        self.dec0 = nn.Linear(in_features=features, out_features=512)\n",
    "        self.dec1 = nn.Linear(in_features=512, out_features=1024)\n",
    "        self.dec2 = nn.Linear(in_features=1024, out_features=84*84)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
    "        return sample\n",
    " \n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc0(x))\n",
    "        x = F.relu(self.enc1(x))\n",
    "\n",
    "        x = self.enc2(x).view(-1, 2, features)\n",
    "\n",
    "        # get `mu` and `log_var`\n",
    "        mu = x[:, 0, :] # the first feature values as mean\n",
    "        log_var = x[:, 1, :] # the other feature values as variance\n",
    "\n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    " \n",
    "        # decoding\n",
    "        x = F.relu(self.dec0(z))\n",
    "        x = F.relu(self.dec1(x))\n",
    "        reconstruction = torch.sigmoid(self.dec2(x))\n",
    "        return z,reconstruction, mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b1b2cd",
   "metadata": {},
   "source": [
    "Parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "410b7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leanring parameters\n",
    "epochs = 10\n",
    "train_games = 100\n",
    "val_games = 20\n",
    "batch_size = 64\n",
    "beta = 10\n",
    "kl_wheight = 1\n",
    "tc_wheight = 0\n",
    "lr = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85457025",
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = f\"C:/Users/erics/Documents/Programme/Bachelorarbeit/beat_VAE_Pong_runs/runTC{tc_wheight}_Beta{beta}Lat{features}\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "    \n",
    "savingDir = newpath + \"/outputBetaMAR21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48f07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_log_density(z_sampled: TensorType[\"batch\", \"num_latents\"],\n",
    "                         z_mean: TensorType[\"batch\", \"num_latents\"],\n",
    "                         z_logvar: TensorType[\"batch\", \"num_latents\"]):\n",
    "    normalization = torch.log(torch.tensor(2. * np.pi))\n",
    "    inv_sigma = torch.exp(-z_logvar)\n",
    "    tmp = (z_sampled - z_mean)\n",
    "    return -0.5 * (tmp * tmp * inv_sigma + z_logvar + normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f38144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_correlation(z: TensorType[\"batch\", \"num_latents\"],\n",
    "                      z_mean: TensorType[\"batch\", \"num_latents\"],\n",
    "                      z_logvar: TensorType[\"batch\", \"num_latents\"]) -> torch.Tensor:\n",
    "    \n",
    "    batch_size = z.size(0)\n",
    "    log_qz_prob = gaussian_log_density(z.unsqueeze(1), z_mean.unsqueeze(0), z_logvar.unsqueeze(0))\n",
    "\n",
    "    log_qz_product = torch.sum(\n",
    "        torch.logsumexp(log_qz_prob, dim=1),\n",
    "        dim=1\n",
    "    )\n",
    "    log_qz = torch.logsumexp(\n",
    "        torch.sum(log_qz_prob, dim=2),\n",
    "        dim=1\n",
    "    )\n",
    "    return torch.mean(log_qz - log_qz_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3660d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_loss(reconstruction_loss, mu, logvar, z_sampled, beta, kl_wheight, tc_wheight):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss (MSELoss) and the (one could also take the mse loss instead of bce then we get a kind of PCA)\n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param bce_loss: recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    :param z_sampled: sample that will be inputed into the decoder\n",
    "    \"\"\"\n",
    "    REC = reconstruction_loss \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    TC = total_correlation(z_sampled, mu, logvar)\n",
    "    return REC + beta*kl_wheight*KLD + tc_wheight * TC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ddbf3",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e50886f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('train_data100kFEB23.npy')\n",
    "val_data = np.load('val_data20kFEB23.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e3f0c",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a1084fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms why do i need a transform?\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5db48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d1ceb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearVAE(\n",
      "  (enc0): Linear(in_features=7056, out_features=1024, bias=True)\n",
      "  (enc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (enc2): Linear(in_features=512, out_features=32, bias=True)\n",
      "  (dec0): Linear(in_features=16, out_features=512, bias=True)\n",
      "  (dec1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (dec2): Linear(in_features=1024, out_features=7056, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LinearVAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "#criterion = torch.nn.MSELoss(reduction = 'sum')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf229fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "594cc251",
   "metadata": {},
   "source": [
    "Training Loop (we train the autoencoder on one image in the buffer not on the total buffer. This could also be a nice feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7087e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "   # with torch.profiler.profile(schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=10),\n",
    "   #                             on_trace_ready=torch.profiler.tensorboard_trace_handler('C:/Users/erics/Documents/Programme/Bachelorarbeit/Profiler/BVAE/Linear_MAR8/'),\n",
    "   #                             record_shapes=True,\n",
    "   #                             profile_memory=True,\n",
    "   #                             with_stack=True) as prof: \n",
    "        \n",
    "   #     prof.start()\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
    "        #data, _ = data\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        z_sampled, reconstruction, mu, logvar = model(data)\n",
    "        mse_loss = criterion(reconstruction, data)\n",
    "        loss = final_loss(mse_loss, mu, logvar, z_sampled, beta, kl_wheight, tc_wheight)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "     #       prof.step()\n",
    "\n",
    "     #   prof.stop()\n",
    "\n",
    "    train_loss = running_loss/len(dataloader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30f3c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n",
    "            #data, _ = data\n",
    "            data = data.to(device)\n",
    "            data = data.view(data.size(0), -1)\n",
    "            z_sampled, reconstruction, mu, logvar = model(data)\n",
    "            mse_loss = criterion(reconstruction, data)\n",
    "            loss = final_loss(mse_loss, mu, logvar, z_sampled, beta, kl_wheight, tc_wheight)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            # save the last batch input and output of every epoch\n",
    "            if i == int(len(val_data)/dataloader.batch_size) - 1:\n",
    "                num_rows = 8\n",
    "                both = torch.cat((data.view(batch_size, 1, 84, 84)[:8], \n",
    "                                  reconstruction.view(batch_size, 1, 84, 84)[:8]))\n",
    "                save_image(both.cpu(), savingDir + f\"{epoch}.png\", nrow=num_rows)\n",
    "    val_loss = running_loss/len(dataloader.dataset)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eee987c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [00:52, 30.09it/s]                                                                                              \n",
      "328it [00:02, 158.03it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.8406\n",
      "Val Loss: 2.4073\n",
      "Epoch 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [00:50, 31.25it/s]                                                                                              \n",
      "328it [00:02, 148.93it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2977\n",
      "Val Loss: 2.2571\n",
      "Epoch 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [00:52, 30.36it/s]                                                                                              \n",
      "328it [00:02, 140.36it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2101\n",
      "Val Loss: 2.2112\n",
      "Epoch 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [00:58, 27.27it/s]                                                                                              \n",
      "328it [00:02, 122.08it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1743\n",
      "Val Loss: 2.1817\n",
      "Epoch 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:12, 21.86it/s]                                                                                              \n",
      "328it [00:03, 92.18it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1558\n",
      "Val Loss: 2.1714\n",
      "Epoch 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:20, 19.76it/s]                                                                                              \n",
      "328it [00:03, 91.24it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1445\n",
      "Val Loss: 2.1613\n",
      "Epoch 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:21, 19.58it/s]                                                                                              \n",
      "328it [00:03, 87.50it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1370\n",
      "Val Loss: 2.1541\n",
      "Epoch 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:21, 19.58it/s]                                                                                              \n",
      "328it [00:03, 86.63it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1318\n",
      "Val Loss: 2.1568\n",
      "Epoch 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:21, 19.58it/s]                                                                                              \n",
      "328it [00:03, 93.24it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1289\n",
      "Val Loss: 2.1506\n",
      "Epoch 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [01:21, 19.65it/s]                                                                                              \n",
      "328it [00:03, 92.18it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1262\n",
      "Val Loss: 2.1446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = fit(model, train_loader)\n",
    "    val_epoch_loss = validate(model, val_loader)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'C:/Users/erics/Documents/Programme/Bachelorarbeit/models/BTCVAE_Pong/B=1VAEMAR21')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb60af",
   "metadata": {},
   "source": [
    "ressourcenauslastung GPU: Copy ~22%, vram 100%, 3D 0% CPU ~25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb67ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
