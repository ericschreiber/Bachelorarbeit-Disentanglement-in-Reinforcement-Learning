{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a06f2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchtyping import TensorType\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5e746a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x245f640ce30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 0 \n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "torch.random.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d02a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 16\n",
    "# define a simple linear VAE #until now normal VAE without Beta\n",
    "class LinearVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearVAE, self).__init__()\n",
    " \n",
    "        # encoder 84*84 = 7â€™056\n",
    "        self.enc0 = nn.Linear(in_features=84*84, out_features=1024)\n",
    "        self.enc1 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.enc2 = nn.Linear(in_features=512, out_features=features*2)\n",
    " \n",
    "        # decoder \n",
    "        self.dec0 = nn.Linear(in_features=features, out_features=512)\n",
    "        self.dec1 = nn.Linear(in_features=512, out_features=1024)\n",
    "        self.dec2 = nn.Linear(in_features=1024, out_features=84*84)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
    "        return sample\n",
    " \n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc0(x))\n",
    "        x = F.relu(self.enc1(x))\n",
    "\n",
    "        x = self.enc2(x).view(-1, 2, features)\n",
    "\n",
    "        # get `mu` and `log_var`\n",
    "        mu = x[:, 0, :] # the first feature values as mean\n",
    "        log_var = x[:, 1, :] # the other feature values as variance\n",
    "\n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    " \n",
    "        # decoding\n",
    "        x = F.relu(self.dec0(z))\n",
    "        x = F.relu(self.dec1(x))\n",
    "        reconstruction = torch.sigmoid(self.dec2(x))\n",
    "        return z,reconstruction, mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b1b2cd",
   "metadata": {},
   "source": [
    "Parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410b7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leanring parameters\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "beta = 10\n",
    "kl_wheight = 0.00064\n",
    "tc_wheight = 0\n",
    "lr = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f8a9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = f\"C:/Users/erics/Documents/Programme/Bachelorarbeit/beat_VAE_Pong_runs/runTC{tc_wheight}_Beta{beta}Lat{features}\"\n",
    "newpath = newpath + \"/outputBetaMAR22\"\n",
    "\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "    \n",
    "savingDir = newpath + \"/epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f272fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_log_density(z_sampled: TensorType[\"batch\", \"num_latents\"],\n",
    "                         z_mean: TensorType[\"batch\", \"num_latents\"],\n",
    "                         z_logvar: TensorType[\"batch\", \"num_latents\"]):\n",
    "    normalization = torch.log(torch.tensor(2. * np.pi))\n",
    "    inv_sigma = torch.exp(-z_logvar)\n",
    "    tmp = (z_sampled - z_mean)\n",
    "    return -0.5 * (tmp * tmp * inv_sigma + z_logvar + normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d5a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_correlation(z: TensorType[\"batch\", \"num_latents\"],\n",
    "                      z_mean: TensorType[\"batch\", \"num_latents\"],\n",
    "                      z_logvar: TensorType[\"batch\", \"num_latents\"]) -> torch.Tensor:\n",
    "    \n",
    "    batch_size = z.size(0)\n",
    "    log_qz_prob = gaussian_log_density(z.unsqueeze(1), z_mean.unsqueeze(0), z_logvar.unsqueeze(0))\n",
    "\n",
    "    log_qz_product = torch.sum(\n",
    "        torch.logsumexp(log_qz_prob, dim=1),\n",
    "        dim=1\n",
    "    )\n",
    "    log_qz = torch.logsumexp(\n",
    "        torch.sum(log_qz_prob, dim=2),\n",
    "        dim=1\n",
    "    )\n",
    "    return torch.abs(torch.mean(log_qz - log_qz_product))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3660d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_loss(reconstruction_loss, mu, logvar, z_sampled, beta, kl_wheight, tc_wheight):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss (MSELoss) and the (one could also take the mse loss instead of bce then we get a kind of PCA)\n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param bce_loss: recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    :param z_sampled: sample that will be inputed into the decoder\n",
    "    \"\"\"\n",
    "    REC = reconstruction_loss \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    TC = total_correlation(z_sampled, mu, logvar)\n",
    "    return REC + beta*kl_wheight*KLD + tc_wheight * TC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ddbf3",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50886f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('train_data100kMAR22.npy') #hardcoded random data\n",
    "val_data = np.load('val_data20kMAR22.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e3f0c",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a1084fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms why do i need a transform?\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5db48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d1ceb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearVAE(\n",
      "  (enc0): Linear(in_features=7056, out_features=1024, bias=True)\n",
      "  (enc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (enc2): Linear(in_features=512, out_features=32, bias=True)\n",
      "  (dec0): Linear(in_features=16, out_features=512, bias=True)\n",
      "  (dec1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (dec2): Linear(in_features=1024, out_features=7056, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LinearVAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "#criterion = torch.nn.MSELoss(reduction = 'sum')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf229fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "594cc251",
   "metadata": {},
   "source": [
    "Training Loop (we train the autoencoder on one image in the buffer not on the total buffer. This could also be a nice feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7087e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "   # with torch.profiler.profile(schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=10),\n",
    "   #                             on_trace_ready=torch.profiler.tensorboard_trace_handler('C:/Users/erics/Documents/Programme/Bachelorarbeit/Profiler/BVAE/Linear_MAR8/'),\n",
    "   #                             record_shapes=True,\n",
    "   #                             profile_memory=True,\n",
    "   #                             with_stack=True) as prof: \n",
    "        \n",
    "   #     prof.start()\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
    "        #data, _ = data\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        z_sampled, reconstruction, mu, logvar = model(data)\n",
    "        mse_loss = criterion(reconstruction, data)\n",
    "        loss = final_loss(mse_loss, mu, logvar, z_sampled, beta, kl_wheight, tc_wheight)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "     #       prof.step()\n",
    "\n",
    "     #   prof.stop()\n",
    "\n",
    "    train_loss = running_loss/len(dataloader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30f3c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n",
    "            #data, _ = data\n",
    "            data = data.to(device)\n",
    "            data = data.view(data.size(0), -1)\n",
    "            z_sampled, reconstruction, mu, logvar = model(data)\n",
    "            mse_loss = criterion(reconstruction, data)\n",
    "            loss = final_loss(mse_loss, mu, logvar, z_sampled, beta, kl_wheight, tc_wheight)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            # save the last batch input and output of every epoch\n",
    "            if i == int(len(val_data)/dataloader.batch_size) - 1:\n",
    "                num_rows = 8\n",
    "                both = torch.cat((data.view(batch_size, 1, 84, 84)[:8], \n",
    "                                  reconstruction.view(batch_size, 1, 84, 84)[:8]))\n",
    "                save_image(both.cpu(), savingDir + f\"{epoch}.png\", nrow=num_rows)\n",
    "    val_loss = running_loss/len(dataloader.dataset)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee987c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:50, 30.98it/s]                                                                                              \n",
      "313it [00:01, 158.61it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 76.3804\n",
      "Val Loss: 23.9347\n",
      "Epoch 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:47, 32.57it/s]                                                                                              \n",
      "313it [00:01, 160.28it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14.5540\n",
      "Val Loss: 12.0891\n",
      "Epoch 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:48, 31.90it/s]                                                                                              \n",
      "313it [00:02, 147.46it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11.2901\n",
      "Val Loss: 10.7693\n",
      "Epoch 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:50, 30.73it/s]                                                                                              \n",
      "313it [00:02, 137.51it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.4125\n",
      "Val Loss: 10.2051\n",
      "Epoch 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:51, 30.52it/s]                                                                                              \n",
      "313it [00:02, 151.31it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.9894\n",
      "Val Loss: 9.8838\n",
      "Epoch 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:50, 30.71it/s]                                                                                              \n",
      "313it [00:02, 131.55it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.7617\n",
      "Val Loss: 9.7446\n",
      "Epoch 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:54, 28.88it/s]                                                                                              \n",
      "313it [00:02, 132.86it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.6266\n",
      "Val Loss: 9.6347\n",
      "Epoch 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:54, 28.89it/s]                                                                                              \n",
      "313it [00:02, 124.28it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.5313\n",
      "Val Loss: 9.5534\n",
      "Epoch 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:54, 28.76it/s]                                                                                              \n",
      "313it [00:02, 126.21it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.4760\n",
      "Val Loss: 9.4905\n",
      "Epoch 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:54, 28.74it/s]                                                                                              \n",
      "313it [00:02, 124.00it/s]                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.4358\n",
      "Val Loss: 9.4570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = fit(model, train_loader)\n",
    "    val_epoch_loss = validate(model, val_loader)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8d88dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = \"C:/Users/erics/Documents/Programme/Bachelorarbeit/models/BTCVAE_Pong/\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "torch.save(model.state_dict(), newpath + f\"B{beta}_TC{tc_wheight}_VAEMAR21\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb60af",
   "metadata": {},
   "source": [
    "ressourcenauslastung GPU: Copy ~22%, vram 100%, 3D 0% CPU ~25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb67ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
