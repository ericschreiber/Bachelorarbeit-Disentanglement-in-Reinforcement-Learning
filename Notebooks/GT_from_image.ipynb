{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce805d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a57c611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_data (8000, 4, 84, 84)\n",
      "train_data (30000, 4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "#train = np.load(r\"C:\\Users\\erics\\Documents\\Programme\\Bachelorarbeit\\train_data100kWithLabels.npz\")\n",
    "#val = np.load(r\"C:\\Users\\erics\\Documents\\Programme\\Bachelorarbeit\\val_data100kBWithLabels.npz\")\n",
    "train = np.load(r\"C:\\Users\\erics\\Documents\\Programme\\Bachelorarbeit\\train_data30kBuffer3.npz\")\n",
    "val = np.load(r\"C:\\Users\\erics\\Documents\\Programme\\Bachelorarbeit\\val_data8kBuffer3.npz\")\n",
    "train_data = train['data']\n",
    "train_labels = train['labels']\n",
    "val_data = val['data']\n",
    "val_labels = val['labels']\n",
    "print(f\"val_data {val_data.shape}\")\n",
    "print(f\"train_data {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96996ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = train_data[:,None,:,:]\n",
    "#val_data = val_data[:,None,:,:]\n",
    "\n",
    "train_labels = train_labels.astype(dtype=np.float32)\n",
    "val_labels =  val_labels.astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "399ef51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_data (8000, 4, 4)\n",
      "val_data (8000, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_data {val_labels.shape}\")\n",
    "train_labels = train_labels.reshape(-1,16)\n",
    "val_labels = val_labels.reshape(-1,16)\n",
    "print(f\"val_data {val_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e114b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=4, stride=2, padding=1)  # 42 x 42\n",
    "        self.conv2 = nn.Conv2d(32, 32, 2, 2, 1)  # 21 x 21\n",
    "        self.conv3 = nn.Conv2d(32, 64, 2, 2, 1)  # 11 x 11\n",
    "        self.conv4 = nn.Conv2d(64, 64, 2, 2, 1)  # 6 x 6\n",
    "        self.flat1 = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(3136, 256) # 6x6x 64 = 2304\n",
    "        self.dense2 = nn.Linear(256, 4*num_channels)\n",
    "        \n",
    "        self.BN0 = nn.BatchNorm1d(256)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        h = self.act(self.conv1(x))\n",
    "        #print(\"conv1: \" + str(h.size()))\n",
    "        h = self.act(self.conv2(h))\n",
    "        #print(\"conv2: \" + str(h.size()))\n",
    "        h = self.act(self.conv3(h))\n",
    "        #print(\"conv3: \" + str(h.size()))\n",
    "        h = self.act(self.conv4(h))\n",
    "        #print(\"conv4: \" + str(h.size()))\n",
    "        h = self.flat1(h)\n",
    "        #print(h.size())\n",
    "        h = self.act(self.BN0(self.dense1(h)))\n",
    "        #print(h.size())\n",
    "        return self.dense2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7159b3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e692dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(4, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
      "  (flat1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dense1): Linear(in_features=3136, out_features=256, bias=True)\n",
      "  (dense2): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (BN0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net(train_data.shape[1]).to(device) #labels.shape[1] ).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b57d48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=lr)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28d7c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, inpX, inp_labels):\n",
    "    inpX = inpX#.to(device)\n",
    "    inp_labels = inp_labels#.to(device)\n",
    "    model.train\n",
    "    train_loss = []\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(0, len(inp_labels)-batch_size, batch_size):\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"i: {i/10000}\")   \n",
    "        \n",
    "        running_loss = 0.0\n",
    "        X = inpX[i:(i+batch_size)].to(device)\n",
    "        labels = inp_labels[i:i+batch_size].to(device)\n",
    "        #print(X.device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "\n",
    "        inp = model(X)#.detach().cpu()\n",
    "        #inp = inp.view(inp.shape[0])\n",
    "        output = loss(inp, labels)\n",
    "        \n",
    "        correct += (torch.round(inp) == labels).float().sum()\n",
    "\n",
    "        \n",
    "        \n",
    "        output.retain_grad()\n",
    "        output.backward()\n",
    "        running_loss += output.item()\n",
    "        \n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        train_loss.append(running_loss)\n",
    "    accuracy = correct/len(inp_labels)\n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac666923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, X, labels):\n",
    "    inpX = X#.to(device)\n",
    "    inp_labels = labels#.to(device)\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    correct = 0  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(inp_labels)-batch_size, batch_size):\n",
    "            if i % 10000 == 0:\n",
    "                print(f\"i: {i/10000}\")   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            X = inpX[i:(i+batch_size)].to(device)\n",
    "            labels = inp_labels[i:i+batch_size].to(device)\n",
    "            #print(X.device)\n",
    "\n",
    "            inp = model(X)#.detach().cpu()\n",
    "            #inp = inp.view(inp.shape[0])\n",
    "\n",
    "            correct += (torch.round(inp) == labels).float().sum()\n",
    "\n",
    "\n",
    "            output = loss(inp, labels)\n",
    "            running_loss += output.item()\n",
    "            \n",
    "            val_loss.append(running_loss)\n",
    "            \n",
    "    accuracy = correct/len(inp_labels)\n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a49e3e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.06450754314812104, Train Accuracy: 15.19123363494873\n",
      "Val Loss: 0.05501704945801252, Validation Accuracy: 15.254000663757324\n",
      "Epoch 2 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.049677193568365426, Train Accuracy: 15.357033729553223\n",
      "Val Loss: 0.05318641004313427, Validation Accuracy: 15.273250579833984\n",
      "Epoch 3 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.046474179495503705, Train Accuracy: 15.389900207519531\n",
      "Val Loss: 0.05049479993651191, Validation Accuracy: 15.303125381469727\n",
      "Epoch 4 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.04474106737936319, Train Accuracy: 15.409000396728516\n",
      "Val Loss: 0.0506600650797886, Validation Accuracy: 15.303376197814941\n",
      "Epoch 5 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.043251980603011594, Train Accuracy: 15.42473316192627\n",
      "Val Loss: 0.049648710807044825, Validation Accuracy: 15.30612564086914\n",
      "Epoch 6 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.042177500537215966, Train Accuracy: 15.4353666305542\n",
      "Val Loss: 0.04951860642726402, Validation Accuracy: 15.310750961303711\n",
      "Epoch 7 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.04098783366843311, Train Accuracy: 15.447466850280762\n",
      "Val Loss: 0.04880961296279507, Validation Accuracy: 15.321125984191895\n",
      "Epoch 8 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.04010218315088889, Train Accuracy: 15.456666946411133\n",
      "Val Loss: 0.04841450764143084, Validation Accuracy: 15.325875282287598\n",
      "Epoch 9 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03935306955212399, Train Accuracy: 15.46756649017334\n",
      "Val Loss: 0.04767880817673292, Validation Accuracy: 15.335000991821289\n",
      "Epoch 10 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03850865603316269, Train Accuracy: 15.477200508117676\n",
      "Val Loss: 0.04762293664686172, Validation Accuracy: 15.339750289916992\n",
      "Epoch 11 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.037988109180153114, Train Accuracy: 15.485166549682617\n",
      "Val Loss: 0.046678694316661024, Validation Accuracy: 15.339500427246094\n",
      "Epoch 12 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03739988752079207, Train Accuracy: 15.49233341217041\n",
      "Val Loss: 0.04635272030699923, Validation Accuracy: 15.347625732421875\n",
      "Epoch 13 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03675669997735714, Train Accuracy: 15.497400283813477\n",
      "Val Loss: 0.046346439609685576, Validation Accuracy: 15.346000671386719\n",
      "Epoch 14 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03632700905152134, Train Accuracy: 15.505766868591309\n",
      "Val Loss: 0.04734922206425762, Validation Accuracy: 15.345376014709473\n",
      "Epoch 15 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.035925557081495176, Train Accuracy: 15.508233070373535\n",
      "Val Loss: 0.04543167083378298, Validation Accuracy: 15.357501029968262\n",
      "Epoch 16 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03537094725838593, Train Accuracy: 15.516133308410645\n",
      "Val Loss: 0.04556235358358387, Validation Accuracy: 15.357125282287598\n",
      "Epoch 17 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.035155473960804075, Train Accuracy: 15.520233154296875\n",
      "Val Loss: 0.04493496609649744, Validation Accuracy: 15.363375663757324\n",
      "Epoch 18 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.0345793138899251, Train Accuracy: 15.52536678314209\n",
      "Val Loss: 0.04568744517384045, Validation Accuracy: 15.364251136779785\n",
      "Epoch 19 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03425963183024077, Train Accuracy: 15.529133796691895\n",
      "Val Loss: 0.04471245865116876, Validation Accuracy: 15.362125396728516\n",
      "Epoch 20 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03371073310775335, Train Accuracy: 15.534867286682129\n",
      "Val Loss: 0.044051235399571766, Validation Accuracy: 15.364625930786133\n",
      "Epoch 21 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03337214594426602, Train Accuracy: 15.538866996765137\n",
      "Val Loss: 0.04456013055839931, Validation Accuracy: 15.366625785827637\n",
      "Epoch 22 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03311272687204143, Train Accuracy: 15.54246711730957\n",
      "Val Loss: 0.043876746968631766, Validation Accuracy: 15.371625900268555\n",
      "Epoch 23 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.032856085580220025, Train Accuracy: 15.546833038330078\n",
      "Val Loss: 0.04423047271538451, Validation Accuracy: 15.370125770568848\n",
      "Epoch 24 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.032679949881133236, Train Accuracy: 15.548999786376953\n",
      "Val Loss: 0.04381823557687093, Validation Accuracy: 15.375125885009766\n",
      "Epoch 25 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03244232678171665, Train Accuracy: 15.551933288574219\n",
      "Val Loss: 0.04376062581756986, Validation Accuracy: 15.373625755310059\n",
      "Epoch 26 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03209957450314195, Train Accuracy: 15.555366516113281\n",
      "Val Loss: 0.043707735582168804, Validation Accuracy: 15.372876167297363\n",
      "Epoch 27 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03171013509148976, Train Accuracy: 15.560033798217773\n",
      "Val Loss: 0.04396296925393932, Validation Accuracy: 15.3722505569458\n",
      "Epoch 28 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.031486002406306175, Train Accuracy: 15.562767028808594\n",
      "Val Loss: 0.04417697339501965, Validation Accuracy: 15.3725004196167\n",
      "Epoch 29 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.031135798772854637, Train Accuracy: 15.567399978637695\n",
      "Val Loss: 0.04388207374477243, Validation Accuracy: 15.375125885009766\n",
      "Epoch 30 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.030853560236118648, Train Accuracy: 15.569833755493164\n",
      "Val Loss: 0.04373544902656691, Validation Accuracy: 15.380250930786133\n",
      "Epoch 31 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.030709517276830963, Train Accuracy: 15.572000503540039\n",
      "Val Loss: 0.04331137948336611, Validation Accuracy: 15.381250381469727\n",
      "Epoch 32 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03055712608809373, Train Accuracy: 15.574867248535156\n",
      "Val Loss: 0.044446003978630626, Validation Accuracy: 15.38162612915039\n",
      "Epoch 33 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.030449835954307555, Train Accuracy: 15.57800006866455\n",
      "Val Loss: 0.04303203194390937, Validation Accuracy: 15.382250785827637\n",
      "Epoch 34 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.030315952596186066, Train Accuracy: 15.578900337219238\n",
      "Val Loss: 0.043667609006705056, Validation Accuracy: 15.38162612915039\n",
      "Epoch 35 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.030227929665811417, Train Accuracy: 15.5823335647583\n",
      "Val Loss: 0.043046480583318746, Validation Accuracy: 15.384500503540039\n",
      "Epoch 36 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02969150688785467, Train Accuracy: 15.58626651763916\n",
      "Val Loss: 0.04282609691252431, Validation Accuracy: 15.390501022338867\n",
      "Epoch 37 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.029569743609646277, Train Accuracy: 15.587533950805664\n",
      "Val Loss: 0.04228850752938105, Validation Accuracy: 15.393250465393066\n",
      "Epoch 38 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02940830984128005, Train Accuracy: 15.58983325958252\n",
      "Val Loss: 0.042960241268647004, Validation Accuracy: 15.397126197814941\n",
      "Epoch 39 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02936423603910456, Train Accuracy: 15.593000411987305\n",
      "Val Loss: 0.04270070851462553, Validation Accuracy: 15.395000457763672\n",
      "Epoch 40 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.029262168769274413, Train Accuracy: 15.595067024230957\n",
      "Val Loss: 0.04225471987198275, Validation Accuracy: 15.393625259399414\n",
      "Epoch 41 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02911529827290468, Train Accuracy: 15.598133087158203\n",
      "Val Loss: 0.04180762476201756, Validation Accuracy: 15.397750854492188\n",
      "Epoch 42 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.029253954306372076, Train Accuracy: 15.598233222961426\n",
      "Val Loss: 0.04181867265647434, Validation Accuracy: 15.395376205444336\n",
      "Epoch 43 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.029272921138871442, Train Accuracy: 15.599733352661133\n",
      "Val Loss: 0.04246399130477723, Validation Accuracy: 15.399750709533691\n",
      "Epoch 44 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.029083947815088478, Train Accuracy: 15.604833602905273\n",
      "Val Loss: 0.04239540618571292, Validation Accuracy: 15.393625259399414\n",
      "Epoch 45 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.029055926025414736, Train Accuracy: 15.606500625610352\n",
      "Val Loss: 0.04329499389123486, Validation Accuracy: 15.388626098632812\n",
      "Epoch 46 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02920237619612712, Train Accuracy: 15.607566833496094\n",
      "Val Loss: 0.045037093748110366, Validation Accuracy: 15.383251190185547\n",
      "Epoch 47 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03057272291544471, Train Accuracy: 15.604433059692383\n",
      "Val Loss: 0.04534279377046359, Validation Accuracy: 15.378251075744629\n",
      "Epoch 48 of 80\n",
      "i: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.03220372571507538, Train Accuracy: 15.594066619873047\n",
      "Val Loss: 0.04623421429690108, Validation Accuracy: 15.375125885009766\n",
      "Epoch 49 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.031603100717568666, Train Accuracy: 15.595200538635254\n",
      "Val Loss: 0.0427121719622229, Validation Accuracy: 15.400500297546387\n",
      "Epoch 50 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.029109021362509646, Train Accuracy: 15.611599922180176\n",
      "Val Loss: 0.04257099174082758, Validation Accuracy: 15.400500297546387\n",
      "Epoch 51 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.027538593013630732, Train Accuracy: 15.616033554077148\n",
      "Val Loss: 0.040706139929353236, Validation Accuracy: 15.414000511169434\n",
      "Epoch 52 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02613135694407857, Train Accuracy: 15.622233390808105\n",
      "Val Loss: 0.04141635143284099, Validation Accuracy: 15.407751083374023\n",
      "Epoch 53 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02673022893208736, Train Accuracy: 15.620599746704102\n",
      "Val Loss: 0.04158669986937898, Validation Accuracy: 15.410250663757324\n",
      "Epoch 54 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02678145786991846, Train Accuracy: 15.622233390808105\n",
      "Val Loss: 0.04225097656489376, Validation Accuracy: 15.40837574005127\n",
      "Epoch 55 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.026775522672411217, Train Accuracy: 15.624733924865723\n",
      "Val Loss: 0.04281895898701436, Validation Accuracy: 15.405750274658203\n",
      "Epoch 56 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.026641438751935705, Train Accuracy: 15.625967025756836\n",
      "Val Loss: 0.042438448679794266, Validation Accuracy: 15.403375625610352\n",
      "Epoch 57 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.026521260233888184, Train Accuracy: 15.627266883850098\n",
      "Val Loss: 0.04318714722332705, Validation Accuracy: 15.406500816345215\n",
      "Epoch 58 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.026300504224190016, Train Accuracy: 15.631033897399902\n",
      "Val Loss: 0.0418172985629504, Validation Accuracy: 15.412375450134277\n",
      "Epoch 59 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02632945186876977, Train Accuracy: 15.631999969482422\n",
      "Val Loss: 0.042001819178222655, Validation Accuracy: 15.411625862121582\n",
      "Epoch 60 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.026131606825777472, Train Accuracy: 15.633867263793945\n",
      "Val Loss: 0.041491751301001356, Validation Accuracy: 15.413625717163086\n",
      "Epoch 61 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.026332084091505475, Train Accuracy: 15.635000228881836\n",
      "Val Loss: 0.04098681206010791, Validation Accuracy: 15.417375564575195\n",
      "Epoch 62 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.0262052245167747, Train Accuracy: 15.637633323669434\n",
      "Val Loss: 0.04066940375704722, Validation Accuracy: 15.4191255569458\n",
      "Epoch 63 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02585980969430479, Train Accuracy: 15.639933586120605\n",
      "Val Loss: 0.04015488381381614, Validation Accuracy: 15.423625946044922\n",
      "Epoch 64 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.025497466393347865, Train Accuracy: 15.641300201416016\n",
      "Val Loss: 0.040633733066389836, Validation Accuracy: 15.422375679016113\n",
      "Epoch 65 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.025694635694721274, Train Accuracy: 15.642300605773926\n",
      "Val Loss: 0.04003238729219959, Validation Accuracy: 15.421375274658203\n",
      "Epoch 66 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02554275969633775, Train Accuracy: 15.644766807556152\n",
      "Val Loss: 0.04034844812858535, Validation Accuracy: 15.418750762939453\n",
      "Epoch 67 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.025600073811386414, Train Accuracy: 15.646599769592285\n",
      "Val Loss: 0.04061975020047531, Validation Accuracy: 15.417500495910645\n",
      "Epoch 68 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.025418085562961778, Train Accuracy: 15.647299766540527\n",
      "Val Loss: 0.04055893077444001, Validation Accuracy: 15.41925048828125\n",
      "Epoch 69 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.025608580892462294, Train Accuracy: 15.648900032043457\n",
      "Val Loss: 0.04001090063687309, Validation Accuracy: 15.426250457763672\n",
      "Epoch 70 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02582474160351042, Train Accuracy: 15.651433944702148\n",
      "Val Loss: 0.04101886202667253, Validation Accuracy: 15.422125816345215\n",
      "Epoch 71 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.026684604761098275, Train Accuracy: 15.651333808898926\n",
      "Val Loss: 0.04082320571454414, Validation Accuracy: 15.424625396728516\n",
      "Epoch 72 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.026840153805267466, Train Accuracy: 15.652899742126465\n",
      "Val Loss: 0.04041725246003833, Validation Accuracy: 15.425875663757324\n",
      "Epoch 73 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.027508139773296827, Train Accuracy: 15.650799751281738\n",
      "Val Loss: 0.041061821464733424, Validation Accuracy: 15.424625396728516\n",
      "Epoch 74 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02819214195605435, Train Accuracy: 15.646900177001953\n",
      "Val Loss: 0.04172323154936354, Validation Accuracy: 15.422125816345215\n",
      "Epoch 75 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.027827753702311785, Train Accuracy: 15.648966789245605\n",
      "Val Loss: 0.0399065825744087, Validation Accuracy: 15.43112564086914\n",
      "Epoch 76 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.025224415550610745, Train Accuracy: 15.660533905029297\n",
      "Val Loss: 0.03860412153553771, Validation Accuracy: 15.439126014709473\n",
      "Epoch 77 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02332227202997073, Train Accuracy: 15.668733596801758\n",
      "Val Loss: 0.039269473538341294, Validation Accuracy: 15.437251091003418\n",
      "Epoch 78 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.023722457305877097, Train Accuracy: 15.668100357055664\n",
      "Val Loss: 0.039538534073884704, Validation Accuracy: 15.438750267028809\n",
      "Epoch 79 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.02413895189774043, Train Accuracy: 15.66883373260498\n",
      "Val Loss: 0.040040435108644176, Validation Accuracy: 15.436875343322754\n",
      "Epoch 80 of 80\n",
      "i: 0.0\n",
      "i: 2.0\n",
      "i: 0.0\n",
      "Train Loss: 0.024138008587245244, Train Accuracy: 15.673299789428711\n",
      "Val Loss: 0.04114392609990026, Validation Accuracy: 15.432750701904297\n",
      "Train Loss: [0.06450754314812104, 0.049677193568365426, 0.046474179495503705, 0.04474106737936319, 0.043251980603011594, 0.042177500537215966, 0.04098783366843311, 0.04010218315088889, 0.03935306955212399, 0.03850865603316269, 0.037988109180153114, 0.03739988752079207, 0.03675669997735714, 0.03632700905152134, 0.035925557081495176, 0.03537094725838593, 0.035155473960804075, 0.0345793138899251, 0.03425963183024077, 0.03371073310775335, 0.03337214594426602, 0.03311272687204143, 0.032856085580220025, 0.032679949881133236, 0.03244232678171665, 0.03209957450314195, 0.03171013509148976, 0.031486002406306175, 0.031135798772854637, 0.030853560236118648, 0.030709517276830963, 0.03055712608809373, 0.030449835954307555, 0.030315952596186066, 0.030227929665811417, 0.02969150688785467, 0.029569743609646277, 0.02940830984128005, 0.02936423603910456, 0.029262168769274413, 0.02911529827290468, 0.029253954306372076, 0.029272921138871442, 0.029083947815088478, 0.029055926025414736, 0.02920237619612712, 0.03057272291544471, 0.03220372571507538, 0.031603100717568666, 0.029109021362509646, 0.027538593013630732, 0.02613135694407857, 0.02673022893208736, 0.02678145786991846, 0.026775522672411217, 0.026641438751935705, 0.026521260233888184, 0.026300504224190016, 0.02632945186876977, 0.026131606825777472, 0.026332084091505475, 0.0262052245167747, 0.02585980969430479, 0.025497466393347865, 0.025694635694721274, 0.02554275969633775, 0.025600073811386414, 0.025418085562961778, 0.025608580892462294, 0.02582474160351042, 0.026684604761098275, 0.026840153805267466, 0.027508139773296827, 0.02819214195605435, 0.027827753702311785, 0.025224415550610745, 0.02332227202997073, 0.023722457305877097, 0.02413895189774043, 0.024138008587245244], Train Accuracy: [tensor(15.1912, device='cuda:0'), tensor(15.3570, device='cuda:0'), tensor(15.3899, device='cuda:0'), tensor(15.4090, device='cuda:0'), tensor(15.4247, device='cuda:0'), tensor(15.4354, device='cuda:0'), tensor(15.4475, device='cuda:0'), tensor(15.4567, device='cuda:0'), tensor(15.4676, device='cuda:0'), tensor(15.4772, device='cuda:0'), tensor(15.4852, device='cuda:0'), tensor(15.4923, device='cuda:0'), tensor(15.4974, device='cuda:0'), tensor(15.5058, device='cuda:0'), tensor(15.5082, device='cuda:0'), tensor(15.5161, device='cuda:0'), tensor(15.5202, device='cuda:0'), tensor(15.5254, device='cuda:0'), tensor(15.5291, device='cuda:0'), tensor(15.5349, device='cuda:0'), tensor(15.5389, device='cuda:0'), tensor(15.5425, device='cuda:0'), tensor(15.5468, device='cuda:0'), tensor(15.5490, device='cuda:0'), tensor(15.5519, device='cuda:0'), tensor(15.5554, device='cuda:0'), tensor(15.5600, device='cuda:0'), tensor(15.5628, device='cuda:0'), tensor(15.5674, device='cuda:0'), tensor(15.5698, device='cuda:0'), tensor(15.5720, device='cuda:0'), tensor(15.5749, device='cuda:0'), tensor(15.5780, device='cuda:0'), tensor(15.5789, device='cuda:0'), tensor(15.5823, device='cuda:0'), tensor(15.5863, device='cuda:0'), tensor(15.5875, device='cuda:0'), tensor(15.5898, device='cuda:0'), tensor(15.5930, device='cuda:0'), tensor(15.5951, device='cuda:0'), tensor(15.5981, device='cuda:0'), tensor(15.5982, device='cuda:0'), tensor(15.5997, device='cuda:0'), tensor(15.6048, device='cuda:0'), tensor(15.6065, device='cuda:0'), tensor(15.6076, device='cuda:0'), tensor(15.6044, device='cuda:0'), tensor(15.5941, device='cuda:0'), tensor(15.5952, device='cuda:0'), tensor(15.6116, device='cuda:0'), tensor(15.6160, device='cuda:0'), tensor(15.6222, device='cuda:0'), tensor(15.6206, device='cuda:0'), tensor(15.6222, device='cuda:0'), tensor(15.6247, device='cuda:0'), tensor(15.6260, device='cuda:0'), tensor(15.6273, device='cuda:0'), tensor(15.6310, device='cuda:0'), tensor(15.6320, device='cuda:0'), tensor(15.6339, device='cuda:0'), tensor(15.6350, device='cuda:0'), tensor(15.6376, device='cuda:0'), tensor(15.6399, device='cuda:0'), tensor(15.6413, device='cuda:0'), tensor(15.6423, device='cuda:0'), tensor(15.6448, device='cuda:0'), tensor(15.6466, device='cuda:0'), tensor(15.6473, device='cuda:0'), tensor(15.6489, device='cuda:0'), tensor(15.6514, device='cuda:0'), tensor(15.6513, device='cuda:0'), tensor(15.6529, device='cuda:0'), tensor(15.6508, device='cuda:0'), tensor(15.6469, device='cuda:0'), tensor(15.6490, device='cuda:0'), tensor(15.6605, device='cuda:0'), tensor(15.6687, device='cuda:0'), tensor(15.6681, device='cuda:0'), tensor(15.6688, device='cuda:0'), tensor(15.6733, device='cuda:0')]\n",
      "Val Loss: [0.05501704945801252, 0.05318641004313427, 0.05049479993651191, 0.0506600650797886, 0.049648710807044825, 0.04951860642726402, 0.04880961296279507, 0.04841450764143084, 0.04767880817673292, 0.04762293664686172, 0.046678694316661024, 0.04635272030699923, 0.046346439609685576, 0.04734922206425762, 0.04543167083378298, 0.04556235358358387, 0.04493496609649744, 0.04568744517384045, 0.04471245865116876, 0.044051235399571766, 0.04456013055839931, 0.043876746968631766, 0.04423047271538451, 0.04381823557687093, 0.04376062581756986, 0.043707735582168804, 0.04396296925393932, 0.04417697339501965, 0.04388207374477243, 0.04373544902656691, 0.04331137948336611, 0.044446003978630626, 0.04303203194390937, 0.043667609006705056, 0.043046480583318746, 0.04282609691252431, 0.04228850752938105, 0.042960241268647004, 0.04270070851462553, 0.04225471987198275, 0.04180762476201756, 0.04181867265647434, 0.04246399130477723, 0.04239540618571292, 0.04329499389123486, 0.045037093748110366, 0.04534279377046359, 0.04623421429690108, 0.0427121719622229, 0.04257099174082758, 0.040706139929353236, 0.04141635143284099, 0.04158669986937898, 0.04225097656489376, 0.04281895898701436, 0.042438448679794266, 0.04318714722332705, 0.0418172985629504, 0.042001819178222655, 0.041491751301001356, 0.04098681206010791, 0.04066940375704722, 0.04015488381381614, 0.040633733066389836, 0.04003238729219959, 0.04034844812858535, 0.04061975020047531, 0.04055893077444001, 0.04001090063687309, 0.04101886202667253, 0.04082320571454414, 0.04041725246003833, 0.041061821464733424, 0.04172323154936354, 0.0399065825744087, 0.03860412153553771, 0.039269473538341294, 0.039538534073884704, 0.040040435108644176, 0.04114392609990026], Validation Accuracy: [tensor(15.2540, device='cuda:0'), tensor(15.2733, device='cuda:0'), tensor(15.3031, device='cuda:0'), tensor(15.3034, device='cuda:0'), tensor(15.3061, device='cuda:0'), tensor(15.3108, device='cuda:0'), tensor(15.3211, device='cuda:0'), tensor(15.3259, device='cuda:0'), tensor(15.3350, device='cuda:0'), tensor(15.3398, device='cuda:0'), tensor(15.3395, device='cuda:0'), tensor(15.3476, device='cuda:0'), tensor(15.3460, device='cuda:0'), tensor(15.3454, device='cuda:0'), tensor(15.3575, device='cuda:0'), tensor(15.3571, device='cuda:0'), tensor(15.3634, device='cuda:0'), tensor(15.3643, device='cuda:0'), tensor(15.3621, device='cuda:0'), tensor(15.3646, device='cuda:0'), tensor(15.3666, device='cuda:0'), tensor(15.3716, device='cuda:0'), tensor(15.3701, device='cuda:0'), tensor(15.3751, device='cuda:0'), tensor(15.3736, device='cuda:0'), tensor(15.3729, device='cuda:0'), tensor(15.3723, device='cuda:0'), tensor(15.3725, device='cuda:0'), tensor(15.3751, device='cuda:0'), tensor(15.3803, device='cuda:0'), tensor(15.3813, device='cuda:0'), tensor(15.3816, device='cuda:0'), tensor(15.3823, device='cuda:0'), tensor(15.3816, device='cuda:0'), tensor(15.3845, device='cuda:0'), tensor(15.3905, device='cuda:0'), tensor(15.3933, device='cuda:0'), tensor(15.3971, device='cuda:0'), tensor(15.3950, device='cuda:0'), tensor(15.3936, device='cuda:0'), tensor(15.3978, device='cuda:0'), tensor(15.3954, device='cuda:0'), tensor(15.3998, device='cuda:0'), tensor(15.3936, device='cuda:0'), tensor(15.3886, device='cuda:0'), tensor(15.3833, device='cuda:0'), tensor(15.3783, device='cuda:0'), tensor(15.3751, device='cuda:0'), tensor(15.4005, device='cuda:0'), tensor(15.4005, device='cuda:0'), tensor(15.4140, device='cuda:0'), tensor(15.4078, device='cuda:0'), tensor(15.4103, device='cuda:0'), tensor(15.4084, device='cuda:0'), tensor(15.4058, device='cuda:0'), tensor(15.4034, device='cuda:0'), tensor(15.4065, device='cuda:0'), tensor(15.4124, device='cuda:0'), tensor(15.4116, device='cuda:0'), tensor(15.4136, device='cuda:0'), tensor(15.4174, device='cuda:0'), tensor(15.4191, device='cuda:0'), tensor(15.4236, device='cuda:0'), tensor(15.4224, device='cuda:0'), tensor(15.4214, device='cuda:0'), tensor(15.4188, device='cuda:0'), tensor(15.4175, device='cuda:0'), tensor(15.4193, device='cuda:0'), tensor(15.4263, device='cuda:0'), tensor(15.4221, device='cuda:0'), tensor(15.4246, device='cuda:0'), tensor(15.4259, device='cuda:0'), tensor(15.4246, device='cuda:0'), tensor(15.4221, device='cuda:0'), tensor(15.4311, device='cuda:0'), tensor(15.4391, device='cuda:0'), tensor(15.4373, device='cuda:0'), tensor(15.4388, device='cuda:0'), tensor(15.4369, device='cuda:0'), tensor(15.4328, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "torch.backends.cudnn.benchmark = True #choose best kernel for computation\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "\n",
    "    train_epoch_loss, train_accuracy = fit(model, torch.from_numpy(train_data), torch.from_numpy(train_labels))\n",
    "    torch.cuda.empty_cache()\n",
    "    val_epoch_loss, val_accuracy = validate(model, torch.from_numpy(val_data), torch.from_numpy(val_labels))\n",
    "    print(f\"Train Loss: {np.mean(np.asarray(train_epoch_loss))}, Train Accuracy: {train_accuracy}\")\n",
    "    print(f\"Val Loss: {np.mean(np.asarray(val_epoch_loss))}, Validation Accuracy: {val_accuracy}\")\n",
    "    train_loss.append(np.mean(np.asarray(train_epoch_loss)))\n",
    "    val_loss.append(np.mean(np.asarray(val_epoch_loss)))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    \n",
    "print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracies}\")\n",
    "print(f\"Val Loss: {val_loss}, Validation Accuracy: {val_accuracies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2256fe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[72.0044, 54.9709, 30.0603, 36.9084, 70.0408, 56.8941, 31.9836, 38.9517,\n",
      "         68.0544, 59.0159, 33.9808, 40.9164, 66.0493, 60.9065, 35.8999, 42.9465]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inp = model(torch.from_numpy(val_data)[20].to(device)[None,:,:,:])\n",
    "print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2105573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72. 55. 30. 37. 70. 57. 32. 39. 68. 59. 34. 41. 66. 61. 36. 43.]\n"
     ]
    }
   ],
   "source": [
    "print(val_labels[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16e04f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"GT_from_Images_Buffer_400E_3-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a0322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
