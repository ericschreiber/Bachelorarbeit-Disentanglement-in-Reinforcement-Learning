{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233c7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06f2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import random\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d02a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 10\n",
    "# define a simple linear VAE #until now normal VAE without Beta\n",
    "class LinearVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearVAE, self).__init__()\n",
    " \n",
    "        # encoder \n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=512)\n",
    "        self.enc2 = nn.Linear(in_features=512, out_features=features*2)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=features, out_features=512)\n",
    "        self.dec2 = nn.Linear(in_features=512, out_features=784)\n",
    "        \n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
    "        return sample\n",
    " \n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = self.enc2(x).view(-1, 2, features)\n",
    "\n",
    "        # get `mu` and `log_var`\n",
    "        mu = x[:, 0, :] # the first feature values as mean\n",
    "        log_var = x[:, 1, :] # the other feature values as variance\n",
    "\n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    " \n",
    "        # decoding\n",
    "        x = F.relu(self.dec1(z))\n",
    "        reconstruction = torch.sigmoid(self.dec2(x))\n",
    "        return reconstruction, mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b1b2cd",
   "metadata": {},
   "source": [
    "Parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "410b7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leanring parameters\n",
    "epochs = 10\n",
    "train_games = 30\n",
    "val_games = 10\n",
    "batch_size = 64\n",
    "beta = 150\n",
    "lr = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3660d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_loss(bce_loss, mu, logvar, beta, kl_wheight):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss (BCELoss) and the (one could also take the mse loss instead of bce)\n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param bce_loss: recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    \"\"\"\n",
    "    BCE = bce_loss \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + beta*kl_wheight*KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a1084fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms why do i need a transform? used it diretly\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79915ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b068ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='./data', train=True, download=True,  transform = ToTensor())\n",
    "val_data = datasets.MNIST(root='./data', train=False, download=True,  transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5db48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d1ceb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearVAE(\n",
      "  (enc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (enc2): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (dec1): Linear(in_features=10, out_features=512, bias=True)\n",
      "  (dec2): Linear(in_features=512, out_features=784, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LinearVAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#criterion = nn.BCELoss(reduction='sum')\n",
    "criterion = torch.nn.MSELoss(reduction = 'sum')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9e379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "594cc251",
   "metadata": {},
   "source": [
    "Training Loop (we train the autoencoder on one image in the buffer not on the total buffer. This could also be a nice feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7087e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
    "        data, _ = data\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        reconstruction, mu, logvar = model(data)\n",
    "        bce_loss = criterion(reconstruction, data)\n",
    "        loss = final_loss(bce_loss, mu, logvar, beta, kl_wheight = dataloader.batch_size/len(train_data))\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = running_loss/len(dataloader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30f3c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n",
    "            data, _ = data\n",
    "            data = data.to(device)\n",
    "            data = data.view(data.size(0), -1)\n",
    "            reconstruction, mu, logvar = model(data)\n",
    "            bce_loss = criterion(reconstruction, data)\n",
    "            loss = final_loss(bce_loss, mu, logvar, beta, kl_wheight = dataloader.batch_size/len(val_data))\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            # save the last batch input and output of every epoch\n",
    "            if i == int(len(val_data)/dataloader.batch_size) - 1:\n",
    "                num_rows = 8\n",
    "                both = torch.cat((data.view(batch_size, 1, 28, 28)[:8], \n",
    "                                  reconstruction.view(batch_size, 1, 28, 28)[:8]))\n",
    "                save_image(both.cpu(), f\"MNISToutput{epoch}.png\", nrow=num_rows)\n",
    "    val_loss = running_loss/len(dataloader.dataset)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eee987c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:12, 74.00it/s]                                                                                               \n",
      "157it [00:01, 100.16it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 27.9726\n",
      "Val Loss: 47.2227\n",
      "Epoch 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:13, 69.96it/s]                                                                                               \n",
      "157it [00:01, 99.71it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 24.3459\n",
      "Val Loss: 43.6279\n",
      "Epoch 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:13, 69.63it/s]                                                                                               \n",
      "157it [00:01, 85.53it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 22.9887\n",
      "Val Loss: 41.5026\n",
      "Epoch 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:13, 71.81it/s]                                                                                               \n",
      "157it [00:01, 102.17it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 22.0560\n",
      "Val Loss: 40.1989\n",
      "Epoch 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:12, 75.12it/s]                                                                                               \n",
      "157it [00:01, 87.73it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 21.3658\n",
      "Val Loss: 39.2782\n",
      "Epoch 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:13, 69.13it/s]                                                                                               \n",
      "157it [00:01, 98.73it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 20.8052\n",
      "Val Loss: 38.5122\n",
      "Epoch 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:13, 67.96it/s]                                                                                               \n",
      "157it [00:01, 96.86it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 20.3612\n",
      "Val Loss: 38.2274\n",
      "Epoch 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:13, 69.51it/s]                                                                                               \n",
      "157it [00:01, 96.84it/s]                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19.9902\n",
      "Val Loss: 37.7074\n",
      "Epoch 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:12, 73.63it/s]                                                                                               \n",
      "157it [00:01, 101.17it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19.6773\n",
      "Val Loss: 37.4635\n",
      "Epoch 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:12, 74.31it/s]                                                                                               \n",
      "157it [00:01, 96.86it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19.4062\n",
      "Val Loss: 37.2062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = fit(model, train_loader)\n",
    "    val_epoch_loss = validate(model, val_loader)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6b227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
